{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting Off\n",
    "\n",
    "How does a random forest algorithm try to correct for the short comings of a decision tree?\n",
    "\n",
    "Your answer should specifically mention the shortcomings of a decision tree and be explicit in how it overcomes that shortcoming. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Methods Applied\n",
    "\n",
    "Agenda:\n",
    "- Review code for Voting Classifier, Bagging Classifier, and Random Forest\n",
    "- Practice finding optimal hyperparameter for  Random Forest with gridsearch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Prep Titanic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestRegressor, ExtraTreesRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data and split data to be used in the models\n",
    "titanic = pd.read_csv('https://raw.githubusercontent.com/learn-co-students/nyc-ds-033020-lectures/master/Mod_3/decision_trees/cleaned_titanic.csv', index_col='PassengerId')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create matrix of features\n",
    "X = titanic.drop('Survived', axis = 1) # grabs everything else but 'Survived'\n",
    "\n",
    "# Create target variable\n",
    "y = titanic['Survived'] # y is the column we're trying to predict\n",
    "\n",
    "# Create a list of the features being used in the \n",
    "feature_cols = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use x and y variables to split the training data into train and test set then scale that data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7770700636942675\n"
     ]
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)\n",
    "\n",
    "knn_preds = knn.predict(X_test)\n",
    "\n",
    "knn_f1 = metrics.f1_score(y_test, knn_preds)\n",
    "\n",
    "\n",
    "print(knn_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a Logistic Regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8066298342541436\n"
     ]
    }
   ],
   "source": [
    "lr_preds = lr.predict(X_test)\n",
    "\n",
    "lr_f1 = metrics.f1_score(y_test, lr_preds)\n",
    "\n",
    "print(lr_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8047337278106509\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=5, class_weight='balanced')\n",
    "\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "dtc_preds  = dtc.predict(X_test)\n",
    "\n",
    "dtc_f1 = metrics.f1_score(y_test, dtc_preds)\n",
    "\n",
    "print(dtc_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine three models using Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the estimators, we must provide a list of tuples. The first value in the tuple is is the name given to the model/estimator in the second value. SKlearn requires this because there is additional functionality where you can access information about the specific models, so you need to name the models to access them later.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8255813953488372\n"
     ]
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "                estimators=[('logreg', lr), ('knneighbors', knn), ('decisiontree', dtc)], \n",
    "                voting='hard')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "vc_preds = voting_clf.predict(X_test)\n",
    "\n",
    "vc_f1 = metrics.f1_score(y_test, vc_preds)\n",
    "\n",
    "print(vc_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a voting classifier with multiple Logistic regression models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "C_param_range = [0.001,0.01,0.1,1,10]\n",
    "titles = ['lr_0_001', 'lr_0_01', 'lr_0_1', 'lr_1', 'lr_10']\n",
    "\n",
    "params = dict(zip(titles, C_param_range)) \n",
    "models = {}\n",
    "\n",
    "table = pd.DataFrame(columns = ['C_parameter','F1'])\n",
    "table['C_parameter'] = C_param_range\n",
    "j = 0\n",
    "\n",
    "for k , v  in params.items():\n",
    "    \n",
    "    # Create model using different value for c  \n",
    "    lr = LogisticRegression(penalty = 'l2', C = v, random_state = 1, class_weight='balanced')\n",
    "    \n",
    "    #save the model to a dictionary to use later in our voting classifiers\n",
    "    models[k]= lr\n",
    "    \n",
    "    #the steps below this point are unnecessary in order to create a voting classifier, \n",
    "    #but it is easy to fit the model and see how performance changes for different levels of regularization\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict using model\n",
    "    y_preds = lr.predict(X_test)\n",
    "\n",
    "    # Saving accuracy score in table\n",
    "    table.iloc[j,1] = metrics.f1_score(y_test, y_preds)\n",
    "    j += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr_0_001': LogisticRegression(C=0.001, class_weight='balanced', random_state=1),\n",
       " 'lr_0_01': LogisticRegression(C=0.01, class_weight='balanced', random_state=1),\n",
       " 'lr_0_1': LogisticRegression(C=0.1, class_weight='balanced', random_state=1),\n",
       " 'lr_1': LogisticRegression(C=1, class_weight='balanced', random_state=1),\n",
       " 'lr_10': LogisticRegression(C=10, class_weight='balanced', random_state=1)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_parameter</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.735135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.751381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.804469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.80663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.80663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C_parameter        F1\n",
       "0        0.001  0.735135\n",
       "1        0.010  0.751381\n",
       "2        0.100  0.804469\n",
       "3        1.000   0.80663\n",
       "4       10.000   0.80663"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#review performance for different levels of C\n",
    "table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have programmatically created multiple logistic regression models, let's use them in an ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8255813953488372\n"
     ]
    }
   ],
   "source": [
    "lr_voting = VotingClassifier(estimators=list(models.items()), \n",
    "                              voting='hard')\n",
    "\n",
    "lr_voting.fit(X_train, y_train)\n",
    "\n",
    "lrv_preds = voting_clf.predict(X_test)\n",
    "\n",
    "lrv_f1 = metrics.f1_score(y_test, lrv_preds)\n",
    "\n",
    "print(lrv_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a Bagging Classifier for a Logistic Regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_lr = BaggingClassifier(\n",
    "            base_estimator=LogisticRegression(random_state = 1, class_weight='balanced'), \n",
    "            n_estimators= 100,\n",
    "            max_samples= .7,\n",
    "            max_features= 6,\n",
    "            oob_score= True\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=LogisticRegression(C=1.0,\n",
       "                                                    class_weight='balanced',\n",
       "                                                    dual=False,\n",
       "                                                    fit_intercept=True,\n",
       "                                                    intercept_scaling=1,\n",
       "                                                    l1_ratio=None, max_iter=100,\n",
       "                                                    multi_class='auto',\n",
       "                                                    n_jobs=None, penalty='l2',\n",
       "                                                    random_state=1,\n",
       "                                                    solver='lbfgs', tol=0.0001,\n",
       "                                                    verbose=0,\n",
       "                                                    warm_start=False),\n",
       "                  bootstrap=True, bootstrap_features=False, max_features=6,\n",
       "                  max_samples=0.7, n_estimators=100, n_jobs=None,\n",
       "                  oob_score=True, random_state=None, verbose=0,\n",
       "                  warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc_lr.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7762762762762763"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the oob_score to get some idea of how the model performs on a validation set\n",
    "\n",
    "bc_lr.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7826086956521741\n"
     ]
    }
   ],
   "source": [
    "# See how the model performs on the test set\n",
    "\n",
    "bc_lr_preds = bc_lr.predict(X_test)\n",
    "\n",
    "bc_lr_f1 = metrics.f1_score(y_test, bc_lr_preds)\n",
    "\n",
    "print(bc_lr_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***What is the difference in the `VotingClassifier` algorithm and the `BaggingClassifier` algorithm?***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer: Bagging makes many random selections of training data where voting runs each model on all the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the classifier using 100 trees\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state = 1, n_estimators=100, max_depth=1, max_features=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=1, max_features=4, random_state=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's look at all the different default features\n",
    "rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=1, max_features=4, random_state=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model to the training data\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 score:  0.7074829931972789\n"
     ]
    }
   ],
   "source": [
    "#use the fitted model to predict on the test data\n",
    "rfc_preds = rfc.predict(X_test)\n",
    "\n",
    "rfc_f1 = metrics.f1_score(y_test, rfc_preds)\n",
    "\n",
    "# checking accuracy on the test data\n",
    "print('Test F1 score: ', rfc_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Increase the number of trees and see how the model performs***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridsearchCV with Random Forest\n",
    "\n",
    "Let's use grid search to identify the best tuning parameters to use for a random forest model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary of all the parameters you want to tune\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'max_features': [3, 4, 5, 6, 7],\n",
    "    'max_leaf_nodes': [10, 100, 1000, 10000],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_f = RandomForestClassifier(n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(n_estimators=10), n_jobs=-1,\n",
       "             param_grid={'max_depth': [3, 4, 5],\n",
       "                         'max_features': [3, 4, 5, 6, 7],\n",
       "                         'max_leaf_nodes': [10, 100, 1000, 10000]},\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a grid search object and fit it to the data\n",
    "\n",
    "grid_tree = GridSearchCV(estimator=rnd_f, param_grid=param_grid,\n",
    "                    n_jobs=-1, verbose=1, cv=3, scoring='f1')\n",
    "grid_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.703646</td>\n",
       "      <td>0.037216</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 3, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.663249</td>\n",
       "      <td>0.033413</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 3, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.687032</td>\n",
       "      <td>0.043245</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 3, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.706554</td>\n",
       "      <td>0.018585</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 3, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.694313</td>\n",
       "      <td>0.020183</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 4, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.684691</td>\n",
       "      <td>0.047636</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 4, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.709877</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 4, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.698220</td>\n",
       "      <td>0.003335</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 4, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.693479</td>\n",
       "      <td>0.028483</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 5, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.678071</td>\n",
       "      <td>0.048839</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 5, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.680623</td>\n",
       "      <td>0.023914</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 5, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.719568</td>\n",
       "      <td>0.030245</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 5, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.702291</td>\n",
       "      <td>0.035273</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 6, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.693199</td>\n",
       "      <td>0.035327</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 6, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.699676</td>\n",
       "      <td>0.023745</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 6, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.700518</td>\n",
       "      <td>0.034213</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 6, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.691737</td>\n",
       "      <td>0.024509</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 7, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.704982</td>\n",
       "      <td>0.040502</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 7, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.702979</td>\n",
       "      <td>0.020382</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 7, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.692688</td>\n",
       "      <td>0.015106</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 7, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.733271</td>\n",
       "      <td>0.029368</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 3, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.720899</td>\n",
       "      <td>0.027124</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 3, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.716619</td>\n",
       "      <td>0.042026</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 3, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.692870</td>\n",
       "      <td>0.031541</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 3, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.706948</td>\n",
       "      <td>0.019254</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 4, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.700830</td>\n",
       "      <td>0.014341</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 4, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.708183</td>\n",
       "      <td>0.032636</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 4, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.728990</td>\n",
       "      <td>0.024186</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 4, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.708499</td>\n",
       "      <td>0.018256</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 5, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.691001</td>\n",
       "      <td>0.027241</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 5, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.716355</td>\n",
       "      <td>0.035143</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 5, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.717782</td>\n",
       "      <td>0.023536</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 5, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.704815</td>\n",
       "      <td>0.034369</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 6, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.710567</td>\n",
       "      <td>0.037998</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 6, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.691713</td>\n",
       "      <td>0.028431</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 6, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.691696</td>\n",
       "      <td>0.025355</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 6, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.708468</td>\n",
       "      <td>0.036291</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 7, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.714993</td>\n",
       "      <td>0.041725</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 7, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.709471</td>\n",
       "      <td>0.036831</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 7, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.713607</td>\n",
       "      <td>0.032927</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 7, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.718584</td>\n",
       "      <td>0.012560</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 3, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.743515</td>\n",
       "      <td>0.021672</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 3, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.735469</td>\n",
       "      <td>0.035565</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 3, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.730999</td>\n",
       "      <td>0.024583</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 3, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.708676</td>\n",
       "      <td>0.021639</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 4, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.717194</td>\n",
       "      <td>0.020624</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 4, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.729040</td>\n",
       "      <td>0.017007</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 4, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.714288</td>\n",
       "      <td>0.006829</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 4, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.697832</td>\n",
       "      <td>0.045448</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 5, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.718217</td>\n",
       "      <td>0.017270</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 5, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.712770</td>\n",
       "      <td>0.022983</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 5, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.723274</td>\n",
       "      <td>0.022485</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 5, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.727223</td>\n",
       "      <td>0.023851</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 6, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.735333</td>\n",
       "      <td>0.006521</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 6, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.713506</td>\n",
       "      <td>0.036110</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 6, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.734581</td>\n",
       "      <td>0.026104</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 6, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.700116</td>\n",
       "      <td>0.027386</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 7, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.716482</td>\n",
       "      <td>0.033343</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 7, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.717839</td>\n",
       "      <td>0.038805</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 7, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.717654</td>\n",
       "      <td>0.011330</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 7, 'max_leaf_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score  std_test_score  \\\n",
       "0          0.703646        0.037216   \n",
       "1          0.663249        0.033413   \n",
       "2          0.687032        0.043245   \n",
       "3          0.706554        0.018585   \n",
       "4          0.694313        0.020183   \n",
       "5          0.684691        0.047636   \n",
       "6          0.709877        0.006211   \n",
       "7          0.698220        0.003335   \n",
       "8          0.693479        0.028483   \n",
       "9          0.678071        0.048839   \n",
       "10         0.680623        0.023914   \n",
       "11         0.719568        0.030245   \n",
       "12         0.702291        0.035273   \n",
       "13         0.693199        0.035327   \n",
       "14         0.699676        0.023745   \n",
       "15         0.700518        0.034213   \n",
       "16         0.691737        0.024509   \n",
       "17         0.704982        0.040502   \n",
       "18         0.702979        0.020382   \n",
       "19         0.692688        0.015106   \n",
       "20         0.733271        0.029368   \n",
       "21         0.720899        0.027124   \n",
       "22         0.716619        0.042026   \n",
       "23         0.692870        0.031541   \n",
       "24         0.706948        0.019254   \n",
       "25         0.700830        0.014341   \n",
       "26         0.708183        0.032636   \n",
       "27         0.728990        0.024186   \n",
       "28         0.708499        0.018256   \n",
       "29         0.691001        0.027241   \n",
       "30         0.716355        0.035143   \n",
       "31         0.717782        0.023536   \n",
       "32         0.704815        0.034369   \n",
       "33         0.710567        0.037998   \n",
       "34         0.691713        0.028431   \n",
       "35         0.691696        0.025355   \n",
       "36         0.708468        0.036291   \n",
       "37         0.714993        0.041725   \n",
       "38         0.709471        0.036831   \n",
       "39         0.713607        0.032927   \n",
       "40         0.718584        0.012560   \n",
       "41         0.743515        0.021672   \n",
       "42         0.735469        0.035565   \n",
       "43         0.730999        0.024583   \n",
       "44         0.708676        0.021639   \n",
       "45         0.717194        0.020624   \n",
       "46         0.729040        0.017007   \n",
       "47         0.714288        0.006829   \n",
       "48         0.697832        0.045448   \n",
       "49         0.718217        0.017270   \n",
       "50         0.712770        0.022983   \n",
       "51         0.723274        0.022485   \n",
       "52         0.727223        0.023851   \n",
       "53         0.735333        0.006521   \n",
       "54         0.713506        0.036110   \n",
       "55         0.734581        0.026104   \n",
       "56         0.700116        0.027386   \n",
       "57         0.716482        0.033343   \n",
       "58         0.717839        0.038805   \n",
       "59         0.717654        0.011330   \n",
       "\n",
       "                                               params  \n",
       "0   {'max_depth': 3, 'max_features': 3, 'max_leaf_...  \n",
       "1   {'max_depth': 3, 'max_features': 3, 'max_leaf_...  \n",
       "2   {'max_depth': 3, 'max_features': 3, 'max_leaf_...  \n",
       "3   {'max_depth': 3, 'max_features': 3, 'max_leaf_...  \n",
       "4   {'max_depth': 3, 'max_features': 4, 'max_leaf_...  \n",
       "5   {'max_depth': 3, 'max_features': 4, 'max_leaf_...  \n",
       "6   {'max_depth': 3, 'max_features': 4, 'max_leaf_...  \n",
       "7   {'max_depth': 3, 'max_features': 4, 'max_leaf_...  \n",
       "8   {'max_depth': 3, 'max_features': 5, 'max_leaf_...  \n",
       "9   {'max_depth': 3, 'max_features': 5, 'max_leaf_...  \n",
       "10  {'max_depth': 3, 'max_features': 5, 'max_leaf_...  \n",
       "11  {'max_depth': 3, 'max_features': 5, 'max_leaf_...  \n",
       "12  {'max_depth': 3, 'max_features': 6, 'max_leaf_...  \n",
       "13  {'max_depth': 3, 'max_features': 6, 'max_leaf_...  \n",
       "14  {'max_depth': 3, 'max_features': 6, 'max_leaf_...  \n",
       "15  {'max_depth': 3, 'max_features': 6, 'max_leaf_...  \n",
       "16  {'max_depth': 3, 'max_features': 7, 'max_leaf_...  \n",
       "17  {'max_depth': 3, 'max_features': 7, 'max_leaf_...  \n",
       "18  {'max_depth': 3, 'max_features': 7, 'max_leaf_...  \n",
       "19  {'max_depth': 3, 'max_features': 7, 'max_leaf_...  \n",
       "20  {'max_depth': 4, 'max_features': 3, 'max_leaf_...  \n",
       "21  {'max_depth': 4, 'max_features': 3, 'max_leaf_...  \n",
       "22  {'max_depth': 4, 'max_features': 3, 'max_leaf_...  \n",
       "23  {'max_depth': 4, 'max_features': 3, 'max_leaf_...  \n",
       "24  {'max_depth': 4, 'max_features': 4, 'max_leaf_...  \n",
       "25  {'max_depth': 4, 'max_features': 4, 'max_leaf_...  \n",
       "26  {'max_depth': 4, 'max_features': 4, 'max_leaf_...  \n",
       "27  {'max_depth': 4, 'max_features': 4, 'max_leaf_...  \n",
       "28  {'max_depth': 4, 'max_features': 5, 'max_leaf_...  \n",
       "29  {'max_depth': 4, 'max_features': 5, 'max_leaf_...  \n",
       "30  {'max_depth': 4, 'max_features': 5, 'max_leaf_...  \n",
       "31  {'max_depth': 4, 'max_features': 5, 'max_leaf_...  \n",
       "32  {'max_depth': 4, 'max_features': 6, 'max_leaf_...  \n",
       "33  {'max_depth': 4, 'max_features': 6, 'max_leaf_...  \n",
       "34  {'max_depth': 4, 'max_features': 6, 'max_leaf_...  \n",
       "35  {'max_depth': 4, 'max_features': 6, 'max_leaf_...  \n",
       "36  {'max_depth': 4, 'max_features': 7, 'max_leaf_...  \n",
       "37  {'max_depth': 4, 'max_features': 7, 'max_leaf_...  \n",
       "38  {'max_depth': 4, 'max_features': 7, 'max_leaf_...  \n",
       "39  {'max_depth': 4, 'max_features': 7, 'max_leaf_...  \n",
       "40  {'max_depth': 5, 'max_features': 3, 'max_leaf_...  \n",
       "41  {'max_depth': 5, 'max_features': 3, 'max_leaf_...  \n",
       "42  {'max_depth': 5, 'max_features': 3, 'max_leaf_...  \n",
       "43  {'max_depth': 5, 'max_features': 3, 'max_leaf_...  \n",
       "44  {'max_depth': 5, 'max_features': 4, 'max_leaf_...  \n",
       "45  {'max_depth': 5, 'max_features': 4, 'max_leaf_...  \n",
       "46  {'max_depth': 5, 'max_features': 4, 'max_leaf_...  \n",
       "47  {'max_depth': 5, 'max_features': 4, 'max_leaf_...  \n",
       "48  {'max_depth': 5, 'max_features': 5, 'max_leaf_...  \n",
       "49  {'max_depth': 5, 'max_features': 5, 'max_leaf_...  \n",
       "50  {'max_depth': 5, 'max_features': 5, 'max_leaf_...  \n",
       "51  {'max_depth': 5, 'max_features': 5, 'max_leaf_...  \n",
       "52  {'max_depth': 5, 'max_features': 6, 'max_leaf_...  \n",
       "53  {'max_depth': 5, 'max_features': 6, 'max_leaf_...  \n",
       "54  {'max_depth': 5, 'max_features': 6, 'max_leaf_...  \n",
       "55  {'max_depth': 5, 'max_features': 6, 'max_leaf_...  \n",
       "56  {'max_depth': 5, 'max_features': 7, 'max_leaf_...  \n",
       "57  {'max_depth': 5, 'max_features': 7, 'max_leaf_...  \n",
       "58  {'max_depth': 5, 'max_features': 7, 'max_leaf_...  \n",
       "59  {'max_depth': 5, 'max_features': 7, 'max_leaf_...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results = pd.DataFrame(grid_tree.cv_results_)[['mean_test_score', 'std_test_score', 'params']]\n",
    "grid_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     0.663249\n",
       "9     0.678071\n",
       "10    0.680623\n",
       "5     0.684691\n",
       "2     0.687032\n",
       "29    0.691001\n",
       "35    0.691696\n",
       "34    0.691713\n",
       "16    0.691737\n",
       "19    0.692688\n",
       "23    0.692870\n",
       "13    0.693199\n",
       "8     0.693479\n",
       "4     0.694313\n",
       "48    0.697832\n",
       "7     0.698220\n",
       "14    0.699676\n",
       "56    0.700116\n",
       "15    0.700518\n",
       "25    0.700830\n",
       "12    0.702291\n",
       "18    0.702979\n",
       "0     0.703646\n",
       "32    0.704815\n",
       "17    0.704982\n",
       "3     0.706554\n",
       "24    0.706948\n",
       "26    0.708183\n",
       "36    0.708468\n",
       "28    0.708499\n",
       "44    0.708676\n",
       "38    0.709471\n",
       "6     0.709877\n",
       "33    0.710567\n",
       "50    0.712770\n",
       "54    0.713506\n",
       "39    0.713607\n",
       "47    0.714288\n",
       "37    0.714993\n",
       "30    0.716355\n",
       "57    0.716482\n",
       "22    0.716619\n",
       "45    0.717194\n",
       "59    0.717654\n",
       "31    0.717782\n",
       "58    0.717839\n",
       "49    0.718217\n",
       "40    0.718584\n",
       "11    0.719568\n",
       "21    0.720899\n",
       "51    0.723274\n",
       "52    0.727223\n",
       "27    0.728990\n",
       "46    0.729040\n",
       "43    0.730999\n",
       "20    0.733271\n",
       "55    0.734581\n",
       "53    0.735333\n",
       "42    0.735469\n",
       "41    0.743515\n",
       "Name: mean_test_score, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Identify the best params \n",
    "\n",
    "\n",
    "grid_results['mean_test_score'].sort_values()\n",
    "#Identify the best score during fitting with cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict on the test set\n",
    "\n",
    "\n",
    "# checking accuracy\n",
    "\n",
    "\n",
    "# checking accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
