{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# implementation \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "pd.set_option('display.max_columns', 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "titanic = pd.read_csv('https://raw.githubusercontent.com/learn-co-students/nyc-ds-033020-lectures/master/Mod_3/knn/cleaned_titanic.csv', index_col='PassengerId')\n",
    "titanic['youngin'] = titanic['youngin'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data to be used in the models\n",
    "# Create matrix of features\n",
    "X = titanic.drop('Survived', axis = 1) # grabs everything else but 'Survived'\n",
    "\n",
    "# Create target variable\n",
    "y = titanic['Survived'] # y is the column we're trying to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_features_2= PolynomialFeatures(degree=2, include_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly = polynomial_features_2.fit_transform(X)\n",
    "poly_columns = polynomial_features_2.get_feature_names(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>youngin</th>\n",
       "      <th>male</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "      <th>Pclass^2</th>\n",
       "      <th>Pclass Age</th>\n",
       "      <th>Pclass SibSp</th>\n",
       "      <th>Pclass Parch</th>\n",
       "      <th>Pclass Fare</th>\n",
       "      <th>Pclass youngin</th>\n",
       "      <th>Pclass male</th>\n",
       "      <th>Pclass Q</th>\n",
       "      <th>Pclass S</th>\n",
       "      <th>Age^2</th>\n",
       "      <th>Age SibSp</th>\n",
       "      <th>Age Parch</th>\n",
       "      <th>Age Fare</th>\n",
       "      <th>Age youngin</th>\n",
       "      <th>Age male</th>\n",
       "      <th>Age Q</th>\n",
       "      <th>Age S</th>\n",
       "      <th>SibSp^2</th>\n",
       "      <th>SibSp Parch</th>\n",
       "      <th>SibSp Fare</th>\n",
       "      <th>SibSp youngin</th>\n",
       "      <th>SibSp male</th>\n",
       "      <th>SibSp Q</th>\n",
       "      <th>SibSp S</th>\n",
       "      <th>Parch^2</th>\n",
       "      <th>Parch Fare</th>\n",
       "      <th>Parch youngin</th>\n",
       "      <th>Parch male</th>\n",
       "      <th>Parch Q</th>\n",
       "      <th>Parch S</th>\n",
       "      <th>Fare^2</th>\n",
       "      <th>Fare youngin</th>\n",
       "      <th>Fare male</th>\n",
       "      <th>Fare Q</th>\n",
       "      <th>Fare S</th>\n",
       "      <th>youngin^2</th>\n",
       "      <th>youngin male</th>\n",
       "      <th>youngin Q</th>\n",
       "      <th>youngin S</th>\n",
       "      <th>male^2</th>\n",
       "      <th>male Q</th>\n",
       "      <th>male S</th>\n",
       "      <th>Q^2</th>\n",
       "      <th>Q S</th>\n",
       "      <th>S^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>484.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.562500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2708.7654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5081.308859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.7750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>206.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.805625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1225.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1858.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2819.610000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1225.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>281.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.802500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age  SibSp  Parch     Fare  youngin  male    Q    S  Pclass^2  \\\n",
       "0     3.0  22.0    1.0    0.0   7.2500      0.0   1.0  0.0  1.0       9.0   \n",
       "1     1.0  38.0    1.0    0.0  71.2833      0.0   0.0  0.0  0.0       1.0   \n",
       "2     3.0  26.0    0.0    0.0   7.9250      0.0   0.0  0.0  1.0       9.0   \n",
       "3     1.0  35.0    1.0    0.0  53.1000      0.0   0.0  0.0  1.0       1.0   \n",
       "4     3.0  35.0    0.0    0.0   8.0500      0.0   1.0  0.0  1.0       9.0   \n",
       "\n",
       "   Pclass Age  Pclass SibSp  Pclass Parch  Pclass Fare  Pclass youngin  \\\n",
       "0        66.0           3.0           0.0      21.7500             0.0   \n",
       "1        38.0           1.0           0.0      71.2833             0.0   \n",
       "2        78.0           0.0           0.0      23.7750             0.0   \n",
       "3        35.0           1.0           0.0      53.1000             0.0   \n",
       "4       105.0           0.0           0.0      24.1500             0.0   \n",
       "\n",
       "   Pclass male  Pclass Q  Pclass S   Age^2  Age SibSp  Age Parch   Age Fare  \\\n",
       "0          3.0       0.0       3.0   484.0       22.0        0.0   159.5000   \n",
       "1          0.0       0.0       0.0  1444.0       38.0        0.0  2708.7654   \n",
       "2          0.0       0.0       3.0   676.0        0.0        0.0   206.0500   \n",
       "3          0.0       0.0       1.0  1225.0       35.0        0.0  1858.5000   \n",
       "4          3.0       0.0       3.0  1225.0        0.0        0.0   281.7500   \n",
       "\n",
       "   Age youngin  Age male  Age Q  Age S  SibSp^2  SibSp Parch  SibSp Fare  \\\n",
       "0          0.0      22.0    0.0   22.0      1.0          0.0      7.2500   \n",
       "1          0.0       0.0    0.0    0.0      1.0          0.0     71.2833   \n",
       "2          0.0       0.0    0.0   26.0      0.0          0.0      0.0000   \n",
       "3          0.0       0.0    0.0   35.0      1.0          0.0     53.1000   \n",
       "4          0.0      35.0    0.0   35.0      0.0          0.0      0.0000   \n",
       "\n",
       "   SibSp youngin  SibSp male  SibSp Q  SibSp S  Parch^2  Parch Fare  \\\n",
       "0            0.0         1.0      0.0      1.0      0.0         0.0   \n",
       "1            0.0         0.0      0.0      0.0      0.0         0.0   \n",
       "2            0.0         0.0      0.0      0.0      0.0         0.0   \n",
       "3            0.0         0.0      0.0      1.0      0.0         0.0   \n",
       "4            0.0         0.0      0.0      0.0      0.0         0.0   \n",
       "\n",
       "   Parch youngin  Parch male  Parch Q  Parch S       Fare^2  Fare youngin  \\\n",
       "0            0.0         0.0      0.0      0.0    52.562500           0.0   \n",
       "1            0.0         0.0      0.0      0.0  5081.308859           0.0   \n",
       "2            0.0         0.0      0.0      0.0    62.805625           0.0   \n",
       "3            0.0         0.0      0.0      0.0  2819.610000           0.0   \n",
       "4            0.0         0.0      0.0      0.0    64.802500           0.0   \n",
       "\n",
       "   Fare male  Fare Q  Fare S  youngin^2  youngin male  youngin Q  youngin S  \\\n",
       "0       7.25     0.0   7.250        0.0           0.0        0.0        0.0   \n",
       "1       0.00     0.0   0.000        0.0           0.0        0.0        0.0   \n",
       "2       0.00     0.0   7.925        0.0           0.0        0.0        0.0   \n",
       "3       0.00     0.0  53.100        0.0           0.0        0.0        0.0   \n",
       "4       8.05     0.0   8.050        0.0           0.0        0.0        0.0   \n",
       "\n",
       "   male^2  male Q  male S  Q^2  Q S  S^2  \n",
       "0     1.0     0.0     1.0  0.0  0.0  1.0  \n",
       "1     0.0     0.0     0.0  0.0  0.0  0.0  \n",
       "2     0.0     0.0     0.0  0.0  0.0  1.0  \n",
       "3     0.0     0.0     0.0  0.0  0.0  1.0  \n",
       "4     1.0     0.0     1.0  0.0  0.0  1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_poly  = pd.DataFrame(X_poly , columns=poly_columns)\n",
    "X_poly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1c555510>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sns.set(style=\"white\")\n",
    "\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = X_poly.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>youngin</th>\n",
       "      <th>male</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "      <th>Pclass^2</th>\n",
       "      <th>Pclass Age</th>\n",
       "      <th>Pclass SibSp</th>\n",
       "      <th>Pclass Parch</th>\n",
       "      <th>Pclass Fare</th>\n",
       "      <th>Pclass youngin</th>\n",
       "      <th>Pclass male</th>\n",
       "      <th>Pclass Q</th>\n",
       "      <th>Pclass S</th>\n",
       "      <th>Age^2</th>\n",
       "      <th>Age SibSp</th>\n",
       "      <th>Age Parch</th>\n",
       "      <th>Age Fare</th>\n",
       "      <th>Age youngin</th>\n",
       "      <th>Age male</th>\n",
       "      <th>Age Q</th>\n",
       "      <th>Age S</th>\n",
       "      <th>SibSp^2</th>\n",
       "      <th>SibSp Parch</th>\n",
       "      <th>SibSp Fare</th>\n",
       "      <th>SibSp youngin</th>\n",
       "      <th>SibSp male</th>\n",
       "      <th>SibSp Q</th>\n",
       "      <th>SibSp S</th>\n",
       "      <th>Parch^2</th>\n",
       "      <th>Parch Fare</th>\n",
       "      <th>Parch youngin</th>\n",
       "      <th>Parch male</th>\n",
       "      <th>Parch Q</th>\n",
       "      <th>Parch S</th>\n",
       "      <th>Fare^2</th>\n",
       "      <th>Fare youngin</th>\n",
       "      <th>Fare male</th>\n",
       "      <th>Fare Q</th>\n",
       "      <th>Fare S</th>\n",
       "      <th>youngin^2</th>\n",
       "      <th>youngin male</th>\n",
       "      <th>youngin Q</th>\n",
       "      <th>youngin S</th>\n",
       "      <th>male^2</th>\n",
       "      <th>male Q</th>\n",
       "      <th>male S</th>\n",
       "      <th>Q^2</th>\n",
       "      <th>Q S</th>\n",
       "      <th>S^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.405549</td>\n",
       "      <td>0.081656</td>\n",
       "      <td>0.016824</td>\n",
       "      <td>0.548193</td>\n",
       "      <td>0.104190</td>\n",
       "      <td>0.127741</td>\n",
       "      <td>0.220558</td>\n",
       "      <td>0.076466</td>\n",
       "      <td>0.993284</td>\n",
       "      <td>0.477301</td>\n",
       "      <td>0.194339</td>\n",
       "      <td>0.160620</td>\n",
       "      <td>0.317122</td>\n",
       "      <td>0.141809</td>\n",
       "      <td>0.501639</td>\n",
       "      <td>0.235594</td>\n",
       "      <td>0.497822</td>\n",
       "      <td>0.405303</td>\n",
       "      <td>0.066361</td>\n",
       "      <td>0.040453</td>\n",
       "      <td>0.563423</td>\n",
       "      <td>0.106688</td>\n",
       "      <td>0.101962</td>\n",
       "      <td>0.187702</td>\n",
       "      <td>0.133358</td>\n",
       "      <td>0.122429</td>\n",
       "      <td>0.124839</td>\n",
       "      <td>0.121130</td>\n",
       "      <td>0.130312</td>\n",
       "      <td>0.088556</td>\n",
       "      <td>0.072570</td>\n",
       "      <td>0.100380</td>\n",
       "      <td>0.054779</td>\n",
       "      <td>0.212234</td>\n",
       "      <td>0.087608</td>\n",
       "      <td>0.004332</td>\n",
       "      <td>0.060982</td>\n",
       "      <td>0.039831</td>\n",
       "      <td>0.283651</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.307680</td>\n",
       "      <td>0.074089</td>\n",
       "      <td>0.377868</td>\n",
       "      <td>0.104190</td>\n",
       "      <td>0.065358</td>\n",
       "      <td>0.055478</td>\n",
       "      <td>0.075229</td>\n",
       "      <td>0.127741</td>\n",
       "      <td>0.162164</td>\n",
       "      <td>0.131041</td>\n",
       "      <td>0.220558</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.076466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242807</td>\n",
       "      <td>0.170089</td>\n",
       "      <td>0.120938</td>\n",
       "      <td>0.517150</td>\n",
       "      <td>0.083730</td>\n",
       "      <td>0.080875</td>\n",
       "      <td>0.013598</td>\n",
       "      <td>0.397380</td>\n",
       "      <td>0.547827</td>\n",
       "      <td>0.278138</td>\n",
       "      <td>0.192551</td>\n",
       "      <td>0.020461</td>\n",
       "      <td>0.501789</td>\n",
       "      <td>0.102045</td>\n",
       "      <td>0.089588</td>\n",
       "      <td>0.155495</td>\n",
       "      <td>0.952684</td>\n",
       "      <td>0.074841</td>\n",
       "      <td>0.155352</td>\n",
       "      <td>0.369975</td>\n",
       "      <td>0.388210</td>\n",
       "      <td>0.554774</td>\n",
       "      <td>0.013247</td>\n",
       "      <td>0.571350</td>\n",
       "      <td>0.177076</td>\n",
       "      <td>0.223325</td>\n",
       "      <td>0.100850</td>\n",
       "      <td>0.379725</td>\n",
       "      <td>0.189881</td>\n",
       "      <td>0.107698</td>\n",
       "      <td>0.210078</td>\n",
       "      <td>0.031981</td>\n",
       "      <td>0.021493</td>\n",
       "      <td>0.479864</td>\n",
       "      <td>0.144809</td>\n",
       "      <td>0.017762</td>\n",
       "      <td>0.150332</td>\n",
       "      <td>0.060165</td>\n",
       "      <td>0.398010</td>\n",
       "      <td>0.106764</td>\n",
       "      <td>0.041303</td>\n",
       "      <td>0.058655</td>\n",
       "      <td>0.517150</td>\n",
       "      <td>0.369544</td>\n",
       "      <td>0.121038</td>\n",
       "      <td>0.453500</td>\n",
       "      <td>0.083730</td>\n",
       "      <td>0.038506</td>\n",
       "      <td>0.056530</td>\n",
       "      <td>0.080875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.414542</td>\n",
       "      <td>0.160887</td>\n",
       "      <td>0.330293</td>\n",
       "      <td>0.116348</td>\n",
       "      <td>0.026692</td>\n",
       "      <td>0.069438</td>\n",
       "      <td>0.085931</td>\n",
       "      <td>0.207735</td>\n",
       "      <td>0.974283</td>\n",
       "      <td>0.447549</td>\n",
       "      <td>0.426091</td>\n",
       "      <td>0.358753</td>\n",
       "      <td>0.071212</td>\n",
       "      <td>0.030169</td>\n",
       "      <td>0.111562</td>\n",
       "      <td>0.170268</td>\n",
       "      <td>0.823328</td>\n",
       "      <td>0.196140</td>\n",
       "      <td>0.053909</td>\n",
       "      <td>0.306183</td>\n",
       "      <td>0.216614</td>\n",
       "      <td>0.061042</td>\n",
       "      <td>0.105437</td>\n",
       "      <td>0.881671</td>\n",
       "      <td>0.880982</td>\n",
       "      <td>0.759063</td>\n",
       "      <td>0.500619</td>\n",
       "      <td>0.726267</td>\n",
       "      <td>0.228826</td>\n",
       "      <td>0.927300</td>\n",
       "      <td>0.230900</td>\n",
       "      <td>0.281970</td>\n",
       "      <td>0.328443</td>\n",
       "      <td>0.370575</td>\n",
       "      <td>0.057643</td>\n",
       "      <td>0.429773</td>\n",
       "      <td>0.032466</td>\n",
       "      <td>0.274142</td>\n",
       "      <td>0.094406</td>\n",
       "      <td>0.083622</td>\n",
       "      <td>0.257639</td>\n",
       "      <td>0.330293</td>\n",
       "      <td>0.285900</td>\n",
       "      <td>0.211839</td>\n",
       "      <td>0.291855</td>\n",
       "      <td>0.116348</td>\n",
       "      <td>0.017057</td>\n",
       "      <td>0.067642</td>\n",
       "      <td>0.026692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.069438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.217532</td>\n",
       "      <td>0.346635</td>\n",
       "      <td>0.247508</td>\n",
       "      <td>0.081585</td>\n",
       "      <td>0.061512</td>\n",
       "      <td>0.016484</td>\n",
       "      <td>0.133801</td>\n",
       "      <td>0.400555</td>\n",
       "      <td>0.944555</td>\n",
       "      <td>0.392622</td>\n",
       "      <td>0.332526</td>\n",
       "      <td>0.224228</td>\n",
       "      <td>0.078886</td>\n",
       "      <td>0.064870</td>\n",
       "      <td>0.087963</td>\n",
       "      <td>0.315126</td>\n",
       "      <td>0.849833</td>\n",
       "      <td>0.137806</td>\n",
       "      <td>0.294849</td>\n",
       "      <td>0.273704</td>\n",
       "      <td>0.074582</td>\n",
       "      <td>0.062866</td>\n",
       "      <td>0.320331</td>\n",
       "      <td>0.562534</td>\n",
       "      <td>0.360956</td>\n",
       "      <td>0.275563</td>\n",
       "      <td>0.254191</td>\n",
       "      <td>0.024159</td>\n",
       "      <td>0.411382</td>\n",
       "      <td>0.874698</td>\n",
       "      <td>0.619486</td>\n",
       "      <td>0.384992</td>\n",
       "      <td>0.540849</td>\n",
       "      <td>0.211702</td>\n",
       "      <td>0.887374</td>\n",
       "      <td>0.098984</td>\n",
       "      <td>0.306256</td>\n",
       "      <td>0.098136</td>\n",
       "      <td>0.020580</td>\n",
       "      <td>0.295555</td>\n",
       "      <td>0.346635</td>\n",
       "      <td>0.237868</td>\n",
       "      <td>0.051491</td>\n",
       "      <td>0.319470</td>\n",
       "      <td>0.247508</td>\n",
       "      <td>0.071040</td>\n",
       "      <td>0.174840</td>\n",
       "      <td>0.081585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.061512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008379</td>\n",
       "      <td>0.179958</td>\n",
       "      <td>0.116684</td>\n",
       "      <td>0.163758</td>\n",
       "      <td>0.518321</td>\n",
       "      <td>0.340080</td>\n",
       "      <td>0.062695</td>\n",
       "      <td>0.068755</td>\n",
       "      <td>0.909252</td>\n",
       "      <td>0.026485</td>\n",
       "      <td>0.320516</td>\n",
       "      <td>0.124026</td>\n",
       "      <td>0.317594</td>\n",
       "      <td>0.124850</td>\n",
       "      <td>0.216877</td>\n",
       "      <td>0.218098</td>\n",
       "      <td>0.915077</td>\n",
       "      <td>0.014188</td>\n",
       "      <td>0.100407</td>\n",
       "      <td>0.105209</td>\n",
       "      <td>0.096499</td>\n",
       "      <td>0.101183</td>\n",
       "      <td>0.149266</td>\n",
       "      <td>0.412955</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.081588</td>\n",
       "      <td>0.004786</td>\n",
       "      <td>0.119534</td>\n",
       "      <td>0.130052</td>\n",
       "      <td>0.584153</td>\n",
       "      <td>0.010266</td>\n",
       "      <td>0.172737</td>\n",
       "      <td>0.012433</td>\n",
       "      <td>0.153882</td>\n",
       "      <td>0.866095</td>\n",
       "      <td>0.079512</td>\n",
       "      <td>0.600099</td>\n",
       "      <td>0.015989</td>\n",
       "      <td>0.510889</td>\n",
       "      <td>0.008379</td>\n",
       "      <td>0.003584</td>\n",
       "      <td>0.004022</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>0.179958</td>\n",
       "      <td>0.080826</td>\n",
       "      <td>0.207436</td>\n",
       "      <td>0.116684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.163758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youngin</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.076252</td>\n",
       "      <td>0.021512</td>\n",
       "      <td>0.040392</td>\n",
       "      <td>0.095793</td>\n",
       "      <td>0.450017</td>\n",
       "      <td>0.342410</td>\n",
       "      <td>0.353128</td>\n",
       "      <td>0.105895</td>\n",
       "      <td>0.975276</td>\n",
       "      <td>0.044231</td>\n",
       "      <td>0.019381</td>\n",
       "      <td>0.072309</td>\n",
       "      <td>0.300358</td>\n",
       "      <td>0.037465</td>\n",
       "      <td>0.034359</td>\n",
       "      <td>0.134128</td>\n",
       "      <td>0.813867</td>\n",
       "      <td>0.267628</td>\n",
       "      <td>0.065881</td>\n",
       "      <td>0.282117</td>\n",
       "      <td>0.192279</td>\n",
       "      <td>0.298199</td>\n",
       "      <td>0.119316</td>\n",
       "      <td>0.746455</td>\n",
       "      <td>0.259781</td>\n",
       "      <td>0.194758</td>\n",
       "      <td>0.270745</td>\n",
       "      <td>0.144344</td>\n",
       "      <td>0.104191</td>\n",
       "      <td>0.932918</td>\n",
       "      <td>0.301518</td>\n",
       "      <td>0.069037</td>\n",
       "      <td>0.309346</td>\n",
       "      <td>0.030607</td>\n",
       "      <td>0.762911</td>\n",
       "      <td>0.003537</td>\n",
       "      <td>0.035769</td>\n",
       "      <td>0.050270</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.705735</td>\n",
       "      <td>0.245536</td>\n",
       "      <td>0.882095</td>\n",
       "      <td>0.076252</td>\n",
       "      <td>0.024016</td>\n",
       "      <td>0.042008</td>\n",
       "      <td>0.021512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.075217</td>\n",
       "      <td>0.121405</td>\n",
       "      <td>0.131843</td>\n",
       "      <td>0.173907</td>\n",
       "      <td>0.082424</td>\n",
       "      <td>0.221790</td>\n",
       "      <td>0.185347</td>\n",
       "      <td>0.078243</td>\n",
       "      <td>0.867233</td>\n",
       "      <td>0.072493</td>\n",
       "      <td>0.161356</td>\n",
       "      <td>0.075746</td>\n",
       "      <td>0.144453</td>\n",
       "      <td>0.199376</td>\n",
       "      <td>0.141902</td>\n",
       "      <td>0.080499</td>\n",
       "      <td>0.799071</td>\n",
       "      <td>0.055060</td>\n",
       "      <td>0.130360</td>\n",
       "      <td>0.038549</td>\n",
       "      <td>0.087380</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.021002</td>\n",
       "      <td>0.233383</td>\n",
       "      <td>0.027175</td>\n",
       "      <td>0.090338</td>\n",
       "      <td>0.181811</td>\n",
       "      <td>0.129879</td>\n",
       "      <td>0.076694</td>\n",
       "      <td>0.222525</td>\n",
       "      <td>0.040944</td>\n",
       "      <td>0.209780</td>\n",
       "      <td>0.077515</td>\n",
       "      <td>0.040138</td>\n",
       "      <td>0.331042</td>\n",
       "      <td>0.040576</td>\n",
       "      <td>0.125189</td>\n",
       "      <td>0.076252</td>\n",
       "      <td>0.142093</td>\n",
       "      <td>0.049437</td>\n",
       "      <td>0.059933</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.161690</td>\n",
       "      <td>0.729575</td>\n",
       "      <td>0.075217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.121405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.499261</td>\n",
       "      <td>0.229168</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.007634</td>\n",
       "      <td>0.056168</td>\n",
       "      <td>0.100328</td>\n",
       "      <td>0.012337</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.991406</td>\n",
       "      <td>0.420679</td>\n",
       "      <td>0.088276</td>\n",
       "      <td>0.054624</td>\n",
       "      <td>0.056467</td>\n",
       "      <td>0.111645</td>\n",
       "      <td>0.002904</td>\n",
       "      <td>0.088859</td>\n",
       "      <td>0.922553</td>\n",
       "      <td>0.377009</td>\n",
       "      <td>0.017411</td>\n",
       "      <td>0.052160</td>\n",
       "      <td>0.049320</td>\n",
       "      <td>0.038161</td>\n",
       "      <td>0.016014</td>\n",
       "      <td>0.388075</td>\n",
       "      <td>0.119612</td>\n",
       "      <td>0.038392</td>\n",
       "      <td>0.074095</td>\n",
       "      <td>0.036905</td>\n",
       "      <td>0.053632</td>\n",
       "      <td>0.239979</td>\n",
       "      <td>0.123057</td>\n",
       "      <td>0.055465</td>\n",
       "      <td>0.018686</td>\n",
       "      <td>0.076967</td>\n",
       "      <td>0.669023</td>\n",
       "      <td>0.183991</td>\n",
       "      <td>0.021512</td>\n",
       "      <td>0.026371</td>\n",
       "      <td>0.218319</td>\n",
       "      <td>0.074375</td>\n",
       "      <td>0.075217</td>\n",
       "      <td>0.714047</td>\n",
       "      <td>0.305526</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.499261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.051742</td>\n",
       "      <td>0.107301</td>\n",
       "      <td>0.079964</td>\n",
       "      <td>0.071283</td>\n",
       "      <td>0.099595</td>\n",
       "      <td>0.029044</td>\n",
       "      <td>0.132146</td>\n",
       "      <td>0.494970</td>\n",
       "      <td>0.842604</td>\n",
       "      <td>0.015042</td>\n",
       "      <td>0.054818</td>\n",
       "      <td>0.039057</td>\n",
       "      <td>0.168878</td>\n",
       "      <td>0.046986</td>\n",
       "      <td>0.093232</td>\n",
       "      <td>0.460594</td>\n",
       "      <td>0.755135</td>\n",
       "      <td>0.079273</td>\n",
       "      <td>0.112448</td>\n",
       "      <td>0.029275</td>\n",
       "      <td>0.030600</td>\n",
       "      <td>0.052548</td>\n",
       "      <td>0.193750</td>\n",
       "      <td>0.239579</td>\n",
       "      <td>0.059787</td>\n",
       "      <td>0.003909</td>\n",
       "      <td>0.052414</td>\n",
       "      <td>0.037252</td>\n",
       "      <td>0.119812</td>\n",
       "      <td>0.246478</td>\n",
       "      <td>0.138231</td>\n",
       "      <td>0.053434</td>\n",
       "      <td>0.074817</td>\n",
       "      <td>0.334017</td>\n",
       "      <td>0.368528</td>\n",
       "      <td>0.040392</td>\n",
       "      <td>0.038097</td>\n",
       "      <td>0.108998</td>\n",
       "      <td>0.148970</td>\n",
       "      <td>0.121405</td>\n",
       "      <td>0.356495</td>\n",
       "      <td>0.611956</td>\n",
       "      <td>0.499261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass^2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.469051</td>\n",
       "      <td>0.197775</td>\n",
       "      <td>0.159728</td>\n",
       "      <td>0.296008</td>\n",
       "      <td>0.137542</td>\n",
       "      <td>0.504260</td>\n",
       "      <td>0.244717</td>\n",
       "      <td>0.479439</td>\n",
       "      <td>0.397222</td>\n",
       "      <td>0.061114</td>\n",
       "      <td>0.037702</td>\n",
       "      <td>0.532830</td>\n",
       "      <td>0.101798</td>\n",
       "      <td>0.094240</td>\n",
       "      <td>0.194454</td>\n",
       "      <td>0.150149</td>\n",
       "      <td>0.127982</td>\n",
       "      <td>0.129742</td>\n",
       "      <td>0.107790</td>\n",
       "      <td>0.131574</td>\n",
       "      <td>0.091305</td>\n",
       "      <td>0.077647</td>\n",
       "      <td>0.101184</td>\n",
       "      <td>0.057062</td>\n",
       "      <td>0.197777</td>\n",
       "      <td>0.080784</td>\n",
       "      <td>0.006891</td>\n",
       "      <td>0.063651</td>\n",
       "      <td>0.036069</td>\n",
       "      <td>0.265324</td>\n",
       "      <td>0.002886</td>\n",
       "      <td>0.290548</td>\n",
       "      <td>0.082158</td>\n",
       "      <td>0.364083</td>\n",
       "      <td>0.095793</td>\n",
       "      <td>0.059274</td>\n",
       "      <td>0.057906</td>\n",
       "      <td>0.066065</td>\n",
       "      <td>0.131843</td>\n",
       "      <td>0.169108</td>\n",
       "      <td>0.123467</td>\n",
       "      <td>0.229168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.051742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass Age</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.051612</td>\n",
       "      <td>0.282048</td>\n",
       "      <td>0.432512</td>\n",
       "      <td>0.340355</td>\n",
       "      <td>0.108037</td>\n",
       "      <td>0.304725</td>\n",
       "      <td>0.466717</td>\n",
       "      <td>0.017008</td>\n",
       "      <td>0.120157</td>\n",
       "      <td>0.190517</td>\n",
       "      <td>0.326432</td>\n",
       "      <td>0.399919</td>\n",
       "      <td>0.187331</td>\n",
       "      <td>0.431156</td>\n",
       "      <td>0.100048</td>\n",
       "      <td>0.139269</td>\n",
       "      <td>0.198253</td>\n",
       "      <td>0.322947</td>\n",
       "      <td>0.148226</td>\n",
       "      <td>0.070814</td>\n",
       "      <td>0.148459</td>\n",
       "      <td>0.042230</td>\n",
       "      <td>0.173591</td>\n",
       "      <td>0.417410</td>\n",
       "      <td>0.152054</td>\n",
       "      <td>0.035168</td>\n",
       "      <td>0.091407</td>\n",
       "      <td>0.170097</td>\n",
       "      <td>0.351442</td>\n",
       "      <td>0.177123</td>\n",
       "      <td>0.010142</td>\n",
       "      <td>0.245582</td>\n",
       "      <td>0.450017</td>\n",
       "      <td>0.321905</td>\n",
       "      <td>0.100463</td>\n",
       "      <td>0.395362</td>\n",
       "      <td>0.173907</td>\n",
       "      <td>0.097958</td>\n",
       "      <td>0.166454</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.107301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass SibSp</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.466064</td>\n",
       "      <td>0.359520</td>\n",
       "      <td>0.379831</td>\n",
       "      <td>0.008463</td>\n",
       "      <td>0.006520</td>\n",
       "      <td>0.170850</td>\n",
       "      <td>0.204647</td>\n",
       "      <td>0.747683</td>\n",
       "      <td>0.175627</td>\n",
       "      <td>0.032648</td>\n",
       "      <td>0.324682</td>\n",
       "      <td>0.203037</td>\n",
       "      <td>0.048857</td>\n",
       "      <td>0.112776</td>\n",
       "      <td>0.906735</td>\n",
       "      <td>0.892544</td>\n",
       "      <td>0.655490</td>\n",
       "      <td>0.525636</td>\n",
       "      <td>0.724823</td>\n",
       "      <td>0.236845</td>\n",
       "      <td>0.917785</td>\n",
       "      <td>0.226689</td>\n",
       "      <td>0.202377</td>\n",
       "      <td>0.341674</td>\n",
       "      <td>0.369161</td>\n",
       "      <td>0.066449</td>\n",
       "      <td>0.419668</td>\n",
       "      <td>0.016223</td>\n",
       "      <td>0.267952</td>\n",
       "      <td>0.053188</td>\n",
       "      <td>0.071119</td>\n",
       "      <td>0.163923</td>\n",
       "      <td>0.342410</td>\n",
       "      <td>0.295107</td>\n",
       "      <td>0.225889</td>\n",
       "      <td>0.298273</td>\n",
       "      <td>0.082424</td>\n",
       "      <td>0.030679</td>\n",
       "      <td>0.040569</td>\n",
       "      <td>0.007634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.079964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass Parch</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.297146</td>\n",
       "      <td>0.364251</td>\n",
       "      <td>0.161547</td>\n",
       "      <td>0.053419</td>\n",
       "      <td>0.141089</td>\n",
       "      <td>0.117934</td>\n",
       "      <td>0.317153</td>\n",
       "      <td>0.789112</td>\n",
       "      <td>0.006420</td>\n",
       "      <td>0.314677</td>\n",
       "      <td>0.267669</td>\n",
       "      <td>0.051041</td>\n",
       "      <td>0.062751</td>\n",
       "      <td>0.368958</td>\n",
       "      <td>0.591449</td>\n",
       "      <td>0.292451</td>\n",
       "      <td>0.316781</td>\n",
       "      <td>0.289279</td>\n",
       "      <td>0.041532</td>\n",
       "      <td>0.447279</td>\n",
       "      <td>0.884309</td>\n",
       "      <td>0.407403</td>\n",
       "      <td>0.385722</td>\n",
       "      <td>0.484476</td>\n",
       "      <td>0.248915</td>\n",
       "      <td>0.855977</td>\n",
       "      <td>0.003790</td>\n",
       "      <td>0.257603</td>\n",
       "      <td>0.008844</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.154152</td>\n",
       "      <td>0.353128</td>\n",
       "      <td>0.238891</td>\n",
       "      <td>0.066362</td>\n",
       "      <td>0.319323</td>\n",
       "      <td>0.221790</td>\n",
       "      <td>0.054611</td>\n",
       "      <td>0.143366</td>\n",
       "      <td>0.056168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.071283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass Fare</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.099970</td>\n",
       "      <td>0.243987</td>\n",
       "      <td>0.104522</td>\n",
       "      <td>0.159939</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.404211</td>\n",
       "      <td>0.326124</td>\n",
       "      <td>0.792253</td>\n",
       "      <td>0.096264</td>\n",
       "      <td>0.178302</td>\n",
       "      <td>0.099921</td>\n",
       "      <td>0.124716</td>\n",
       "      <td>0.370917</td>\n",
       "      <td>0.423276</td>\n",
       "      <td>0.556697</td>\n",
       "      <td>0.147206</td>\n",
       "      <td>0.291048</td>\n",
       "      <td>0.052073</td>\n",
       "      <td>0.383677</td>\n",
       "      <td>0.276330</td>\n",
       "      <td>0.601863</td>\n",
       "      <td>0.125394</td>\n",
       "      <td>0.293392</td>\n",
       "      <td>0.028279</td>\n",
       "      <td>0.335311</td>\n",
       "      <td>0.779464</td>\n",
       "      <td>0.154134</td>\n",
       "      <td>0.569566</td>\n",
       "      <td>0.004408</td>\n",
       "      <td>0.515470</td>\n",
       "      <td>0.105895</td>\n",
       "      <td>0.094790</td>\n",
       "      <td>0.046778</td>\n",
       "      <td>0.101995</td>\n",
       "      <td>0.185347</td>\n",
       "      <td>0.062459</td>\n",
       "      <td>0.183557</td>\n",
       "      <td>0.100328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.099595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass youngin</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.032189</td>\n",
       "      <td>0.010066</td>\n",
       "      <td>0.084637</td>\n",
       "      <td>0.292543</td>\n",
       "      <td>0.026876</td>\n",
       "      <td>0.032028</td>\n",
       "      <td>0.131336</td>\n",
       "      <td>0.820343</td>\n",
       "      <td>0.259669</td>\n",
       "      <td>0.062614</td>\n",
       "      <td>0.274409</td>\n",
       "      <td>0.217137</td>\n",
       "      <td>0.322838</td>\n",
       "      <td>0.123895</td>\n",
       "      <td>0.791833</td>\n",
       "      <td>0.282429</td>\n",
       "      <td>0.221248</td>\n",
       "      <td>0.289813</td>\n",
       "      <td>0.136333</td>\n",
       "      <td>0.075708</td>\n",
       "      <td>0.898197</td>\n",
       "      <td>0.285387</td>\n",
       "      <td>0.079615</td>\n",
       "      <td>0.291499</td>\n",
       "      <td>0.037830</td>\n",
       "      <td>0.654945</td>\n",
       "      <td>0.010824</td>\n",
       "      <td>0.047570</td>\n",
       "      <td>0.019583</td>\n",
       "      <td>0.975276</td>\n",
       "      <td>0.678357</td>\n",
       "      <td>0.275788</td>\n",
       "      <td>0.840024</td>\n",
       "      <td>0.078243</td>\n",
       "      <td>0.035012</td>\n",
       "      <td>0.048685</td>\n",
       "      <td>0.012337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.029044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass male</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008845</td>\n",
       "      <td>0.345423</td>\n",
       "      <td>0.118418</td>\n",
       "      <td>0.147043</td>\n",
       "      <td>0.204955</td>\n",
       "      <td>0.306674</td>\n",
       "      <td>0.040737</td>\n",
       "      <td>0.563567</td>\n",
       "      <td>0.009666</td>\n",
       "      <td>0.041347</td>\n",
       "      <td>0.009109</td>\n",
       "      <td>0.034939</td>\n",
       "      <td>0.116768</td>\n",
       "      <td>0.025152</td>\n",
       "      <td>0.239657</td>\n",
       "      <td>0.054546</td>\n",
       "      <td>0.048820</td>\n",
       "      <td>0.159764</td>\n",
       "      <td>0.183466</td>\n",
       "      <td>0.049005</td>\n",
       "      <td>0.177699</td>\n",
       "      <td>0.022324</td>\n",
       "      <td>0.175457</td>\n",
       "      <td>0.153102</td>\n",
       "      <td>0.040506</td>\n",
       "      <td>0.065119</td>\n",
       "      <td>0.011624</td>\n",
       "      <td>0.222932</td>\n",
       "      <td>0.044231</td>\n",
       "      <td>0.153170</td>\n",
       "      <td>0.074055</td>\n",
       "      <td>0.037505</td>\n",
       "      <td>0.867233</td>\n",
       "      <td>0.229977</td>\n",
       "      <td>0.656714</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.132146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass Q</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.417064</td>\n",
       "      <td>0.096169</td>\n",
       "      <td>0.064780</td>\n",
       "      <td>0.054432</td>\n",
       "      <td>0.120291</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.091573</td>\n",
       "      <td>0.898680</td>\n",
       "      <td>0.373769</td>\n",
       "      <td>0.017707</td>\n",
       "      <td>0.050585</td>\n",
       "      <td>0.056603</td>\n",
       "      <td>0.040965</td>\n",
       "      <td>0.013198</td>\n",
       "      <td>0.371576</td>\n",
       "      <td>0.118584</td>\n",
       "      <td>0.036480</td>\n",
       "      <td>0.072916</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.051946</td>\n",
       "      <td>0.246057</td>\n",
       "      <td>0.121999</td>\n",
       "      <td>0.057365</td>\n",
       "      <td>0.017112</td>\n",
       "      <td>0.081519</td>\n",
       "      <td>0.589012</td>\n",
       "      <td>0.182410</td>\n",
       "      <td>0.019381</td>\n",
       "      <td>0.028805</td>\n",
       "      <td>0.223848</td>\n",
       "      <td>0.073736</td>\n",
       "      <td>0.072493</td>\n",
       "      <td>0.712636</td>\n",
       "      <td>0.302900</td>\n",
       "      <td>0.991406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.494970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass S</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.156731</td>\n",
       "      <td>0.035216</td>\n",
       "      <td>0.023027</td>\n",
       "      <td>0.328368</td>\n",
       "      <td>0.085732</td>\n",
       "      <td>0.031316</td>\n",
       "      <td>0.388099</td>\n",
       "      <td>0.508399</td>\n",
       "      <td>0.139326</td>\n",
       "      <td>0.169171</td>\n",
       "      <td>0.012721</td>\n",
       "      <td>0.085753</td>\n",
       "      <td>0.089975</td>\n",
       "      <td>0.163255</td>\n",
       "      <td>0.256783</td>\n",
       "      <td>0.081362</td>\n",
       "      <td>0.083967</td>\n",
       "      <td>0.079690</td>\n",
       "      <td>0.048882</td>\n",
       "      <td>0.100954</td>\n",
       "      <td>0.221725</td>\n",
       "      <td>0.188472</td>\n",
       "      <td>0.031950</td>\n",
       "      <td>0.161536</td>\n",
       "      <td>0.281444</td>\n",
       "      <td>0.038802</td>\n",
       "      <td>0.072309</td>\n",
       "      <td>0.055718</td>\n",
       "      <td>0.091842</td>\n",
       "      <td>0.168242</td>\n",
       "      <td>0.161356</td>\n",
       "      <td>0.300385</td>\n",
       "      <td>0.572014</td>\n",
       "      <td>0.420679</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.842604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age^2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.065545</td>\n",
       "      <td>0.155876</td>\n",
       "      <td>0.364175</td>\n",
       "      <td>0.239851</td>\n",
       "      <td>0.550294</td>\n",
       "      <td>0.009765</td>\n",
       "      <td>0.537624</td>\n",
       "      <td>0.135159</td>\n",
       "      <td>0.153858</td>\n",
       "      <td>0.068312</td>\n",
       "      <td>0.223275</td>\n",
       "      <td>0.128502</td>\n",
       "      <td>0.074148</td>\n",
       "      <td>0.150857</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.021652</td>\n",
       "      <td>0.279739</td>\n",
       "      <td>0.058419</td>\n",
       "      <td>0.010685</td>\n",
       "      <td>0.079199</td>\n",
       "      <td>0.050204</td>\n",
       "      <td>0.229577</td>\n",
       "      <td>0.120535</td>\n",
       "      <td>0.041785</td>\n",
       "      <td>0.079452</td>\n",
       "      <td>0.300358</td>\n",
       "      <td>0.212379</td>\n",
       "      <td>0.073104</td>\n",
       "      <td>0.264660</td>\n",
       "      <td>0.075746</td>\n",
       "      <td>0.031240</td>\n",
       "      <td>0.050705</td>\n",
       "      <td>0.088276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age SibSp</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.296359</td>\n",
       "      <td>0.209805</td>\n",
       "      <td>0.012360</td>\n",
       "      <td>0.102452</td>\n",
       "      <td>0.046897</td>\n",
       "      <td>0.068827</td>\n",
       "      <td>0.743856</td>\n",
       "      <td>0.674600</td>\n",
       "      <td>0.725147</td>\n",
       "      <td>0.029853</td>\n",
       "      <td>0.550890</td>\n",
       "      <td>0.091180</td>\n",
       "      <td>0.776287</td>\n",
       "      <td>0.217430</td>\n",
       "      <td>0.278080</td>\n",
       "      <td>0.026705</td>\n",
       "      <td>0.250546</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.342293</td>\n",
       "      <td>0.054920</td>\n",
       "      <td>0.026270</td>\n",
       "      <td>0.119885</td>\n",
       "      <td>0.065557</td>\n",
       "      <td>0.299244</td>\n",
       "      <td>0.037465</td>\n",
       "      <td>0.019803</td>\n",
       "      <td>0.025636</td>\n",
       "      <td>0.033193</td>\n",
       "      <td>0.144453</td>\n",
       "      <td>0.026908</td>\n",
       "      <td>0.094617</td>\n",
       "      <td>0.054624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.054818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age Parch</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.272346</td>\n",
       "      <td>0.002226</td>\n",
       "      <td>0.106678</td>\n",
       "      <td>0.036348</td>\n",
       "      <td>0.117779</td>\n",
       "      <td>0.148198</td>\n",
       "      <td>0.349610</td>\n",
       "      <td>0.227939</td>\n",
       "      <td>0.018185</td>\n",
       "      <td>0.097121</td>\n",
       "      <td>0.020295</td>\n",
       "      <td>0.206722</td>\n",
       "      <td>0.880640</td>\n",
       "      <td>0.599484</td>\n",
       "      <td>0.022263</td>\n",
       "      <td>0.415603</td>\n",
       "      <td>0.220841</td>\n",
       "      <td>0.762557</td>\n",
       "      <td>0.112827</td>\n",
       "      <td>0.025276</td>\n",
       "      <td>0.119994</td>\n",
       "      <td>0.012875</td>\n",
       "      <td>0.271279</td>\n",
       "      <td>0.034359</td>\n",
       "      <td>0.029186</td>\n",
       "      <td>0.010109</td>\n",
       "      <td>0.025533</td>\n",
       "      <td>0.199376</td>\n",
       "      <td>0.063868</td>\n",
       "      <td>0.150965</td>\n",
       "      <td>0.056467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age Fare</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.102809</td>\n",
       "      <td>0.039378</td>\n",
       "      <td>0.090104</td>\n",
       "      <td>0.030858</td>\n",
       "      <td>0.017322</td>\n",
       "      <td>0.041464</td>\n",
       "      <td>0.263627</td>\n",
       "      <td>0.097471</td>\n",
       "      <td>0.012074</td>\n",
       "      <td>0.026760</td>\n",
       "      <td>0.026212</td>\n",
       "      <td>0.105279</td>\n",
       "      <td>0.496139</td>\n",
       "      <td>0.123248</td>\n",
       "      <td>0.127907</td>\n",
       "      <td>0.016724</td>\n",
       "      <td>0.087192</td>\n",
       "      <td>0.802463</td>\n",
       "      <td>0.098446</td>\n",
       "      <td>0.580436</td>\n",
       "      <td>0.015351</td>\n",
       "      <td>0.433579</td>\n",
       "      <td>0.134128</td>\n",
       "      <td>0.094845</td>\n",
       "      <td>0.031651</td>\n",
       "      <td>0.117158</td>\n",
       "      <td>0.141902</td>\n",
       "      <td>0.078409</td>\n",
       "      <td>0.181548</td>\n",
       "      <td>0.111645</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.168878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age youngin</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.206298</td>\n",
       "      <td>0.048280</td>\n",
       "      <td>0.208648</td>\n",
       "      <td>0.189303</td>\n",
       "      <td>0.288588</td>\n",
       "      <td>0.108611</td>\n",
       "      <td>0.672642</td>\n",
       "      <td>0.223110</td>\n",
       "      <td>0.211401</td>\n",
       "      <td>0.249945</td>\n",
       "      <td>0.129299</td>\n",
       "      <td>0.076514</td>\n",
       "      <td>0.786072</td>\n",
       "      <td>0.224068</td>\n",
       "      <td>0.076944</td>\n",
       "      <td>0.282425</td>\n",
       "      <td>0.030324</td>\n",
       "      <td>0.585055</td>\n",
       "      <td>0.011231</td>\n",
       "      <td>0.050544</td>\n",
       "      <td>0.033515</td>\n",
       "      <td>0.813867</td>\n",
       "      <td>0.527130</td>\n",
       "      <td>0.261206</td>\n",
       "      <td>0.745539</td>\n",
       "      <td>0.080499</td>\n",
       "      <td>0.039129</td>\n",
       "      <td>0.048128</td>\n",
       "      <td>0.002904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.046986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age male</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013687</td>\n",
       "      <td>0.385994</td>\n",
       "      <td>0.120916</td>\n",
       "      <td>0.173940</td>\n",
       "      <td>0.137725</td>\n",
       "      <td>0.192830</td>\n",
       "      <td>0.031318</td>\n",
       "      <td>0.057508</td>\n",
       "      <td>0.178005</td>\n",
       "      <td>0.171053</td>\n",
       "      <td>0.106513</td>\n",
       "      <td>0.249989</td>\n",
       "      <td>0.056711</td>\n",
       "      <td>0.060843</td>\n",
       "      <td>0.240830</td>\n",
       "      <td>0.039022</td>\n",
       "      <td>0.203961</td>\n",
       "      <td>0.323095</td>\n",
       "      <td>0.056472</td>\n",
       "      <td>0.074934</td>\n",
       "      <td>0.267628</td>\n",
       "      <td>0.169086</td>\n",
       "      <td>0.053247</td>\n",
       "      <td>0.235276</td>\n",
       "      <td>0.799071</td>\n",
       "      <td>0.090640</td>\n",
       "      <td>0.579605</td>\n",
       "      <td>0.088859</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.093232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age Q</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.347811</td>\n",
       "      <td>0.043646</td>\n",
       "      <td>0.070282</td>\n",
       "      <td>0.055482</td>\n",
       "      <td>0.038900</td>\n",
       "      <td>0.031683</td>\n",
       "      <td>0.228691</td>\n",
       "      <td>0.110349</td>\n",
       "      <td>0.021217</td>\n",
       "      <td>0.068575</td>\n",
       "      <td>0.064653</td>\n",
       "      <td>0.068547</td>\n",
       "      <td>0.224184</td>\n",
       "      <td>0.113526</td>\n",
       "      <td>0.049864</td>\n",
       "      <td>0.050693</td>\n",
       "      <td>0.069819</td>\n",
       "      <td>0.638909</td>\n",
       "      <td>0.169742</td>\n",
       "      <td>0.065881</td>\n",
       "      <td>0.038618</td>\n",
       "      <td>0.026208</td>\n",
       "      <td>0.068615</td>\n",
       "      <td>0.055060</td>\n",
       "      <td>0.691357</td>\n",
       "      <td>0.281864</td>\n",
       "      <td>0.922553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.460594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age S</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.058150</td>\n",
       "      <td>0.065924</td>\n",
       "      <td>0.052354</td>\n",
       "      <td>0.208215</td>\n",
       "      <td>0.082631</td>\n",
       "      <td>0.146308</td>\n",
       "      <td>0.017505</td>\n",
       "      <td>0.027638</td>\n",
       "      <td>0.017675</td>\n",
       "      <td>0.258902</td>\n",
       "      <td>0.074344</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.068407</td>\n",
       "      <td>0.093824</td>\n",
       "      <td>0.216000</td>\n",
       "      <td>0.021423</td>\n",
       "      <td>0.252228</td>\n",
       "      <td>0.319378</td>\n",
       "      <td>0.282117</td>\n",
       "      <td>0.202154</td>\n",
       "      <td>0.082308</td>\n",
       "      <td>0.236427</td>\n",
       "      <td>0.130360</td>\n",
       "      <td>0.269202</td>\n",
       "      <td>0.499036</td>\n",
       "      <td>0.377009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.755135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp^2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.909229</td>\n",
       "      <td>0.733831</td>\n",
       "      <td>0.334351</td>\n",
       "      <td>0.660997</td>\n",
       "      <td>0.136869</td>\n",
       "      <td>0.872031</td>\n",
       "      <td>0.174297</td>\n",
       "      <td>0.224229</td>\n",
       "      <td>0.201596</td>\n",
       "      <td>0.310317</td>\n",
       "      <td>0.041418</td>\n",
       "      <td>0.344335</td>\n",
       "      <td>0.015913</td>\n",
       "      <td>0.163054</td>\n",
       "      <td>0.080430</td>\n",
       "      <td>0.035908</td>\n",
       "      <td>0.197588</td>\n",
       "      <td>0.192279</td>\n",
       "      <td>0.184327</td>\n",
       "      <td>0.152475</td>\n",
       "      <td>0.169446</td>\n",
       "      <td>0.038549</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>0.017411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.079273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp Parch</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.748915</td>\n",
       "      <td>0.451933</td>\n",
       "      <td>0.616444</td>\n",
       "      <td>0.086349</td>\n",
       "      <td>0.881379</td>\n",
       "      <td>0.406667</td>\n",
       "      <td>0.396544</td>\n",
       "      <td>0.337288</td>\n",
       "      <td>0.437771</td>\n",
       "      <td>0.030431</td>\n",
       "      <td>0.588410</td>\n",
       "      <td>0.051949</td>\n",
       "      <td>0.262532</td>\n",
       "      <td>0.085060</td>\n",
       "      <td>0.008635</td>\n",
       "      <td>0.272525</td>\n",
       "      <td>0.298199</td>\n",
       "      <td>0.237206</td>\n",
       "      <td>0.116478</td>\n",
       "      <td>0.289015</td>\n",
       "      <td>0.087380</td>\n",
       "      <td>0.017161</td>\n",
       "      <td>0.026140</td>\n",
       "      <td>0.052160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.112448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp Fare</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.208862</td>\n",
       "      <td>0.522061</td>\n",
       "      <td>0.082810</td>\n",
       "      <td>0.709712</td>\n",
       "      <td>0.215262</td>\n",
       "      <td>0.576619</td>\n",
       "      <td>0.131678</td>\n",
       "      <td>0.291162</td>\n",
       "      <td>0.011701</td>\n",
       "      <td>0.356249</td>\n",
       "      <td>0.229251</td>\n",
       "      <td>0.152356</td>\n",
       "      <td>0.186843</td>\n",
       "      <td>0.042406</td>\n",
       "      <td>0.481473</td>\n",
       "      <td>0.119316</td>\n",
       "      <td>0.117528</td>\n",
       "      <td>0.076815</td>\n",
       "      <td>0.114263</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.018905</td>\n",
       "      <td>0.059775</td>\n",
       "      <td>0.049320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.029275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp youngin</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.426476</td>\n",
       "      <td>0.341759</td>\n",
       "      <td>0.409240</td>\n",
       "      <td>0.120176</td>\n",
       "      <td>0.085215</td>\n",
       "      <td>0.731771</td>\n",
       "      <td>0.275649</td>\n",
       "      <td>0.128600</td>\n",
       "      <td>0.260123</td>\n",
       "      <td>0.024977</td>\n",
       "      <td>0.608096</td>\n",
       "      <td>0.022365</td>\n",
       "      <td>0.106277</td>\n",
       "      <td>0.045677</td>\n",
       "      <td>0.746455</td>\n",
       "      <td>0.618822</td>\n",
       "      <td>0.411142</td>\n",
       "      <td>0.659323</td>\n",
       "      <td>0.021002</td>\n",
       "      <td>0.090635</td>\n",
       "      <td>0.014386</td>\n",
       "      <td>0.038161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.030600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp male</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.279313</td>\n",
       "      <td>0.659679</td>\n",
       "      <td>0.125778</td>\n",
       "      <td>0.157558</td>\n",
       "      <td>0.239607</td>\n",
       "      <td>0.549493</td>\n",
       "      <td>0.086491</td>\n",
       "      <td>0.262863</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.230582</td>\n",
       "      <td>0.244075</td>\n",
       "      <td>0.111371</td>\n",
       "      <td>0.168748</td>\n",
       "      <td>0.259781</td>\n",
       "      <td>0.412710</td>\n",
       "      <td>0.284612</td>\n",
       "      <td>0.220559</td>\n",
       "      <td>0.233383</td>\n",
       "      <td>0.082752</td>\n",
       "      <td>0.191910</td>\n",
       "      <td>0.016014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.052548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp Q</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.046418</td>\n",
       "      <td>0.010937</td>\n",
       "      <td>0.010037</td>\n",
       "      <td>0.120711</td>\n",
       "      <td>0.085615</td>\n",
       "      <td>0.320582</td>\n",
       "      <td>0.047755</td>\n",
       "      <td>0.015138</td>\n",
       "      <td>0.140344</td>\n",
       "      <td>0.022065</td>\n",
       "      <td>0.620009</td>\n",
       "      <td>0.071402</td>\n",
       "      <td>0.194758</td>\n",
       "      <td>0.287954</td>\n",
       "      <td>0.857708</td>\n",
       "      <td>0.028863</td>\n",
       "      <td>0.027175</td>\n",
       "      <td>0.405362</td>\n",
       "      <td>0.118567</td>\n",
       "      <td>0.388075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.193750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp S</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.244020</td>\n",
       "      <td>0.268553</td>\n",
       "      <td>0.297508</td>\n",
       "      <td>0.358501</td>\n",
       "      <td>0.028704</td>\n",
       "      <td>0.486181</td>\n",
       "      <td>0.016907</td>\n",
       "      <td>0.239360</td>\n",
       "      <td>0.088858</td>\n",
       "      <td>0.080023</td>\n",
       "      <td>0.328478</td>\n",
       "      <td>0.270745</td>\n",
       "      <td>0.225254</td>\n",
       "      <td>0.026114</td>\n",
       "      <td>0.327073</td>\n",
       "      <td>0.090338</td>\n",
       "      <td>0.085409</td>\n",
       "      <td>0.032614</td>\n",
       "      <td>0.119612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.239579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch^2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.509057</td>\n",
       "      <td>0.186006</td>\n",
       "      <td>0.387636</td>\n",
       "      <td>0.266701</td>\n",
       "      <td>0.805467</td>\n",
       "      <td>0.055431</td>\n",
       "      <td>0.145545</td>\n",
       "      <td>0.054760</td>\n",
       "      <td>0.006799</td>\n",
       "      <td>0.204360</td>\n",
       "      <td>0.144344</td>\n",
       "      <td>0.093628</td>\n",
       "      <td>0.004992</td>\n",
       "      <td>0.140169</td>\n",
       "      <td>0.181811</td>\n",
       "      <td>0.054084</td>\n",
       "      <td>0.117503</td>\n",
       "      <td>0.038392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch Fare</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.137544</td>\n",
       "      <td>0.434722</td>\n",
       "      <td>0.051056</td>\n",
       "      <td>0.525030</td>\n",
       "      <td>0.441081</td>\n",
       "      <td>0.205852</td>\n",
       "      <td>0.384409</td>\n",
       "      <td>0.037754</td>\n",
       "      <td>0.551756</td>\n",
       "      <td>0.104191</td>\n",
       "      <td>0.080545</td>\n",
       "      <td>0.007753</td>\n",
       "      <td>0.107400</td>\n",
       "      <td>0.129879</td>\n",
       "      <td>0.055365</td>\n",
       "      <td>0.110548</td>\n",
       "      <td>0.074095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch youngin</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.317638</td>\n",
       "      <td>0.040474</td>\n",
       "      <td>0.356711</td>\n",
       "      <td>0.022466</td>\n",
       "      <td>0.799714</td>\n",
       "      <td>0.013690</td>\n",
       "      <td>0.008658</td>\n",
       "      <td>0.076845</td>\n",
       "      <td>0.932918</td>\n",
       "      <td>0.644156</td>\n",
       "      <td>0.158307</td>\n",
       "      <td>0.851766</td>\n",
       "      <td>0.076694</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.036159</td>\n",
       "      <td>0.036905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.052414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch male</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033861</td>\n",
       "      <td>0.497190</td>\n",
       "      <td>0.092528</td>\n",
       "      <td>0.288329</td>\n",
       "      <td>0.360873</td>\n",
       "      <td>0.009721</td>\n",
       "      <td>0.211455</td>\n",
       "      <td>0.301518</td>\n",
       "      <td>0.467105</td>\n",
       "      <td>0.112643</td>\n",
       "      <td>0.287670</td>\n",
       "      <td>0.222525</td>\n",
       "      <td>0.013497</td>\n",
       "      <td>0.171496</td>\n",
       "      <td>0.053632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.037252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch Q</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.029531</td>\n",
       "      <td>0.012208</td>\n",
       "      <td>0.049436</td>\n",
       "      <td>0.012877</td>\n",
       "      <td>0.299101</td>\n",
       "      <td>0.044154</td>\n",
       "      <td>0.069037</td>\n",
       "      <td>0.107786</td>\n",
       "      <td>0.334781</td>\n",
       "      <td>0.017848</td>\n",
       "      <td>0.040944</td>\n",
       "      <td>0.119263</td>\n",
       "      <td>0.073320</td>\n",
       "      <td>0.239979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.119812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch S</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.049586</td>\n",
       "      <td>0.294136</td>\n",
       "      <td>0.056396</td>\n",
       "      <td>0.082328</td>\n",
       "      <td>0.384694</td>\n",
       "      <td>0.309346</td>\n",
       "      <td>0.221178</td>\n",
       "      <td>0.026866</td>\n",
       "      <td>0.370874</td>\n",
       "      <td>0.209780</td>\n",
       "      <td>0.087868</td>\n",
       "      <td>0.077980</td>\n",
       "      <td>0.123057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.246478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare^2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014580</td>\n",
       "      <td>0.608850</td>\n",
       "      <td>0.021692</td>\n",
       "      <td>0.251364</td>\n",
       "      <td>0.030607</td>\n",
       "      <td>0.019683</td>\n",
       "      <td>0.010273</td>\n",
       "      <td>0.023604</td>\n",
       "      <td>0.077515</td>\n",
       "      <td>0.039420</td>\n",
       "      <td>0.126522</td>\n",
       "      <td>0.055465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.138231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare youngin</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.071868</td>\n",
       "      <td>0.023950</td>\n",
       "      <td>0.171710</td>\n",
       "      <td>0.762911</td>\n",
       "      <td>0.584623</td>\n",
       "      <td>0.177762</td>\n",
       "      <td>0.717244</td>\n",
       "      <td>0.040138</td>\n",
       "      <td>0.015271</td>\n",
       "      <td>0.010107</td>\n",
       "      <td>0.018686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare male</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>0.259302</td>\n",
       "      <td>0.003537</td>\n",
       "      <td>0.086392</td>\n",
       "      <td>0.022945</td>\n",
       "      <td>0.011093</td>\n",
       "      <td>0.331042</td>\n",
       "      <td>0.016296</td>\n",
       "      <td>0.138743</td>\n",
       "      <td>0.076967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.074817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare Q</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.123094</td>\n",
       "      <td>0.035769</td>\n",
       "      <td>0.086231</td>\n",
       "      <td>0.336962</td>\n",
       "      <td>0.049758</td>\n",
       "      <td>0.040576</td>\n",
       "      <td>0.499889</td>\n",
       "      <td>0.204404</td>\n",
       "      <td>0.669023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.334017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare S</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050270</td>\n",
       "      <td>0.049073</td>\n",
       "      <td>0.040169</td>\n",
       "      <td>0.094393</td>\n",
       "      <td>0.125189</td>\n",
       "      <td>0.131378</td>\n",
       "      <td>0.063313</td>\n",
       "      <td>0.183991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.368528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youngin^2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.705735</td>\n",
       "      <td>0.245536</td>\n",
       "      <td>0.882095</td>\n",
       "      <td>0.076252</td>\n",
       "      <td>0.024016</td>\n",
       "      <td>0.042008</td>\n",
       "      <td>0.021512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youngin male</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.347916</td>\n",
       "      <td>0.641303</td>\n",
       "      <td>0.142093</td>\n",
       "      <td>0.072672</td>\n",
       "      <td>0.122297</td>\n",
       "      <td>0.026371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.038097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youngin Q</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016237</td>\n",
       "      <td>0.049437</td>\n",
       "      <td>0.305749</td>\n",
       "      <td>0.066702</td>\n",
       "      <td>0.218319</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.108998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youngin S</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059933</td>\n",
       "      <td>0.053107</td>\n",
       "      <td>0.016689</td>\n",
       "      <td>0.074375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.148970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male^2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.161690</td>\n",
       "      <td>0.729575</td>\n",
       "      <td>0.075217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.121405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male Q</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.218160</td>\n",
       "      <td>0.714047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.356495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male S</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.305526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q^2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.499261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q S</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S^2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Pclass       Age     SibSp     Parch      Fare   youngin  \\\n",
       "Pclass             NaN  0.405549  0.081656  0.016824  0.548193  0.104190   \n",
       "Age                NaN       NaN  0.242807  0.170089  0.120938  0.517150   \n",
       "SibSp              NaN       NaN       NaN  0.414542  0.160887  0.330293   \n",
       "Parch              NaN       NaN       NaN       NaN  0.217532  0.346635   \n",
       "Fare               NaN       NaN       NaN       NaN       NaN  0.008379   \n",
       "youngin            NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "male               NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Q                  NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "S                  NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Pclass^2           NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Pclass Age         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Pclass SibSp       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Pclass Parch       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Pclass Fare        NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Pclass youngin     NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Pclass male        NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Pclass Q           NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Pclass S           NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Age^2              NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Age SibSp          NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Age Parch          NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Age Fare           NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Age youngin        NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Age male           NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Age Q              NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Age S              NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "SibSp^2            NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "SibSp Parch        NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "SibSp Fare         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "SibSp youngin      NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "SibSp male         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "SibSp Q            NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "SibSp S            NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Parch^2            NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Parch Fare         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Parch youngin      NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Parch male         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Parch Q            NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Parch S            NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Fare^2             NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Fare youngin       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Fare male          NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Fare Q             NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Fare S             NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "youngin^2          NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "youngin male       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "youngin Q          NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "youngin S          NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "male^2             NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "male Q             NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "male S             NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Q^2                NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Q S                NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "S^2                NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "                    male         Q         S  Pclass^2  Pclass Age  \\\n",
       "Pclass          0.127741  0.220558  0.076466  0.993284    0.477301   \n",
       "Age             0.083730  0.080875  0.013598  0.397380    0.547827   \n",
       "SibSp           0.116348  0.026692  0.069438  0.085931    0.207735   \n",
       "Parch           0.247508  0.081585  0.061512  0.016484    0.133801   \n",
       "Fare            0.179958  0.116684  0.163758  0.518321    0.340080   \n",
       "youngin         0.076252  0.021512  0.040392  0.095793    0.450017   \n",
       "male                 NaN  0.075217  0.121405  0.131843    0.173907   \n",
       "Q                    NaN       NaN  0.499261  0.229168    0.103448   \n",
       "S                    NaN       NaN       NaN  0.051742    0.107301   \n",
       "Pclass^2             NaN       NaN       NaN       NaN    0.469051   \n",
       "Pclass Age           NaN       NaN       NaN       NaN         NaN   \n",
       "Pclass SibSp         NaN       NaN       NaN       NaN         NaN   \n",
       "Pclass Parch         NaN       NaN       NaN       NaN         NaN   \n",
       "Pclass Fare          NaN       NaN       NaN       NaN         NaN   \n",
       "Pclass youngin       NaN       NaN       NaN       NaN         NaN   \n",
       "Pclass male          NaN       NaN       NaN       NaN         NaN   \n",
       "Pclass Q             NaN       NaN       NaN       NaN         NaN   \n",
       "Pclass S             NaN       NaN       NaN       NaN         NaN   \n",
       "Age^2                NaN       NaN       NaN       NaN         NaN   \n",
       "Age SibSp            NaN       NaN       NaN       NaN         NaN   \n",
       "Age Parch            NaN       NaN       NaN       NaN         NaN   \n",
       "Age Fare             NaN       NaN       NaN       NaN         NaN   \n",
       "Age youngin          NaN       NaN       NaN       NaN         NaN   \n",
       "Age male             NaN       NaN       NaN       NaN         NaN   \n",
       "Age Q                NaN       NaN       NaN       NaN         NaN   \n",
       "Age S                NaN       NaN       NaN       NaN         NaN   \n",
       "SibSp^2              NaN       NaN       NaN       NaN         NaN   \n",
       "SibSp Parch          NaN       NaN       NaN       NaN         NaN   \n",
       "SibSp Fare           NaN       NaN       NaN       NaN         NaN   \n",
       "SibSp youngin        NaN       NaN       NaN       NaN         NaN   \n",
       "SibSp male           NaN       NaN       NaN       NaN         NaN   \n",
       "SibSp Q              NaN       NaN       NaN       NaN         NaN   \n",
       "SibSp S              NaN       NaN       NaN       NaN         NaN   \n",
       "Parch^2              NaN       NaN       NaN       NaN         NaN   \n",
       "Parch Fare           NaN       NaN       NaN       NaN         NaN   \n",
       "Parch youngin        NaN       NaN       NaN       NaN         NaN   \n",
       "Parch male           NaN       NaN       NaN       NaN         NaN   \n",
       "Parch Q              NaN       NaN       NaN       NaN         NaN   \n",
       "Parch S              NaN       NaN       NaN       NaN         NaN   \n",
       "Fare^2               NaN       NaN       NaN       NaN         NaN   \n",
       "Fare youngin         NaN       NaN       NaN       NaN         NaN   \n",
       "Fare male            NaN       NaN       NaN       NaN         NaN   \n",
       "Fare Q               NaN       NaN       NaN       NaN         NaN   \n",
       "Fare S               NaN       NaN       NaN       NaN         NaN   \n",
       "youngin^2            NaN       NaN       NaN       NaN         NaN   \n",
       "youngin male         NaN       NaN       NaN       NaN         NaN   \n",
       "youngin Q            NaN       NaN       NaN       NaN         NaN   \n",
       "youngin S            NaN       NaN       NaN       NaN         NaN   \n",
       "male^2               NaN       NaN       NaN       NaN         NaN   \n",
       "male Q               NaN       NaN       NaN       NaN         NaN   \n",
       "male S               NaN       NaN       NaN       NaN         NaN   \n",
       "Q^2                  NaN       NaN       NaN       NaN         NaN   \n",
       "Q S                  NaN       NaN       NaN       NaN         NaN   \n",
       "S^2                  NaN       NaN       NaN       NaN         NaN   \n",
       "\n",
       "                Pclass SibSp  Pclass Parch  Pclass Fare  Pclass youngin  \\\n",
       "Pclass              0.194339      0.160620     0.317122        0.141809   \n",
       "Age                 0.278138      0.192551     0.020461        0.501789   \n",
       "SibSp               0.974283      0.447549     0.426091        0.358753   \n",
       "Parch               0.400555      0.944555     0.392622        0.332526   \n",
       "Fare                0.062695      0.068755     0.909252        0.026485   \n",
       "youngin             0.342410      0.353128     0.105895        0.975276   \n",
       "male                0.082424      0.221790     0.185347        0.078243   \n",
       "Q                   0.007634      0.056168     0.100328        0.012337   \n",
       "S                   0.079964      0.071283     0.099595        0.029044   \n",
       "Pclass^2            0.197775      0.159728     0.296008        0.137542   \n",
       "Pclass Age          0.152000      0.051612     0.282048        0.432512   \n",
       "Pclass SibSp             NaN      0.466064     0.359520        0.379831   \n",
       "Pclass Parch             NaN           NaN     0.297146        0.364251   \n",
       "Pclass Fare              NaN           NaN          NaN        0.099970   \n",
       "Pclass youngin           NaN           NaN          NaN             NaN   \n",
       "Pclass male              NaN           NaN          NaN             NaN   \n",
       "Pclass Q                 NaN           NaN          NaN             NaN   \n",
       "Pclass S                 NaN           NaN          NaN             NaN   \n",
       "Age^2                    NaN           NaN          NaN             NaN   \n",
       "Age SibSp                NaN           NaN          NaN             NaN   \n",
       "Age Parch                NaN           NaN          NaN             NaN   \n",
       "Age Fare                 NaN           NaN          NaN             NaN   \n",
       "Age youngin              NaN           NaN          NaN             NaN   \n",
       "Age male                 NaN           NaN          NaN             NaN   \n",
       "Age Q                    NaN           NaN          NaN             NaN   \n",
       "Age S                    NaN           NaN          NaN             NaN   \n",
       "SibSp^2                  NaN           NaN          NaN             NaN   \n",
       "SibSp Parch              NaN           NaN          NaN             NaN   \n",
       "SibSp Fare               NaN           NaN          NaN             NaN   \n",
       "SibSp youngin            NaN           NaN          NaN             NaN   \n",
       "SibSp male               NaN           NaN          NaN             NaN   \n",
       "SibSp Q                  NaN           NaN          NaN             NaN   \n",
       "SibSp S                  NaN           NaN          NaN             NaN   \n",
       "Parch^2                  NaN           NaN          NaN             NaN   \n",
       "Parch Fare               NaN           NaN          NaN             NaN   \n",
       "Parch youngin            NaN           NaN          NaN             NaN   \n",
       "Parch male               NaN           NaN          NaN             NaN   \n",
       "Parch Q                  NaN           NaN          NaN             NaN   \n",
       "Parch S                  NaN           NaN          NaN             NaN   \n",
       "Fare^2                   NaN           NaN          NaN             NaN   \n",
       "Fare youngin             NaN           NaN          NaN             NaN   \n",
       "Fare male                NaN           NaN          NaN             NaN   \n",
       "Fare Q                   NaN           NaN          NaN             NaN   \n",
       "Fare S                   NaN           NaN          NaN             NaN   \n",
       "youngin^2                NaN           NaN          NaN             NaN   \n",
       "youngin male             NaN           NaN          NaN             NaN   \n",
       "youngin Q                NaN           NaN          NaN             NaN   \n",
       "youngin S                NaN           NaN          NaN             NaN   \n",
       "male^2                   NaN           NaN          NaN             NaN   \n",
       "male Q                   NaN           NaN          NaN             NaN   \n",
       "male S                   NaN           NaN          NaN             NaN   \n",
       "Q^2                      NaN           NaN          NaN             NaN   \n",
       "Q S                      NaN           NaN          NaN             NaN   \n",
       "S^2                      NaN           NaN          NaN             NaN   \n",
       "\n",
       "                Pclass male  Pclass Q  Pclass S     Age^2  Age SibSp  \\\n",
       "Pclass             0.501639  0.235594  0.497822  0.405303   0.066361   \n",
       "Age                0.102045  0.089588  0.155495  0.952684   0.074841   \n",
       "SibSp              0.071212  0.030169  0.111562  0.170268   0.823328   \n",
       "Parch              0.224228  0.078886  0.064870  0.087963   0.315126   \n",
       "Fare               0.320516  0.124026  0.317594  0.124850   0.216877   \n",
       "youngin            0.044231  0.019381  0.072309  0.300358   0.037465   \n",
       "male               0.867233  0.072493  0.161356  0.075746   0.144453   \n",
       "Q                  0.001700  0.991406  0.420679  0.088276   0.054624   \n",
       "S                  0.132146  0.494970  0.842604  0.015042   0.054818   \n",
       "Pclass^2           0.504260  0.244717  0.479439  0.397222   0.061114   \n",
       "Pclass Age         0.340355  0.108037  0.304725  0.466717   0.017008   \n",
       "Pclass SibSp       0.008463  0.006520  0.170850  0.204647   0.747683   \n",
       "Pclass Parch       0.161547  0.053419  0.141089  0.117934   0.317153   \n",
       "Pclass Fare        0.243987  0.104522  0.159939  0.001592   0.404211   \n",
       "Pclass youngin     0.032189  0.010066  0.084637  0.292543   0.026876   \n",
       "Pclass male             NaN  0.008845  0.345423  0.118418   0.147043   \n",
       "Pclass Q                NaN       NaN  0.417064  0.096169   0.064780   \n",
       "Pclass S                NaN       NaN       NaN  0.156731   0.035216   \n",
       "Age^2                   NaN       NaN       NaN       NaN   0.065545   \n",
       "Age SibSp               NaN       NaN       NaN       NaN        NaN   \n",
       "Age Parch               NaN       NaN       NaN       NaN        NaN   \n",
       "Age Fare                NaN       NaN       NaN       NaN        NaN   \n",
       "Age youngin             NaN       NaN       NaN       NaN        NaN   \n",
       "Age male                NaN       NaN       NaN       NaN        NaN   \n",
       "Age Q                   NaN       NaN       NaN       NaN        NaN   \n",
       "Age S                   NaN       NaN       NaN       NaN        NaN   \n",
       "SibSp^2                 NaN       NaN       NaN       NaN        NaN   \n",
       "SibSp Parch             NaN       NaN       NaN       NaN        NaN   \n",
       "SibSp Fare              NaN       NaN       NaN       NaN        NaN   \n",
       "SibSp youngin           NaN       NaN       NaN       NaN        NaN   \n",
       "SibSp male              NaN       NaN       NaN       NaN        NaN   \n",
       "SibSp Q                 NaN       NaN       NaN       NaN        NaN   \n",
       "SibSp S                 NaN       NaN       NaN       NaN        NaN   \n",
       "Parch^2                 NaN       NaN       NaN       NaN        NaN   \n",
       "Parch Fare              NaN       NaN       NaN       NaN        NaN   \n",
       "Parch youngin           NaN       NaN       NaN       NaN        NaN   \n",
       "Parch male              NaN       NaN       NaN       NaN        NaN   \n",
       "Parch Q                 NaN       NaN       NaN       NaN        NaN   \n",
       "Parch S                 NaN       NaN       NaN       NaN        NaN   \n",
       "Fare^2                  NaN       NaN       NaN       NaN        NaN   \n",
       "Fare youngin            NaN       NaN       NaN       NaN        NaN   \n",
       "Fare male               NaN       NaN       NaN       NaN        NaN   \n",
       "Fare Q                  NaN       NaN       NaN       NaN        NaN   \n",
       "Fare S                  NaN       NaN       NaN       NaN        NaN   \n",
       "youngin^2               NaN       NaN       NaN       NaN        NaN   \n",
       "youngin male            NaN       NaN       NaN       NaN        NaN   \n",
       "youngin Q               NaN       NaN       NaN       NaN        NaN   \n",
       "youngin S               NaN       NaN       NaN       NaN        NaN   \n",
       "male^2                  NaN       NaN       NaN       NaN        NaN   \n",
       "male Q                  NaN       NaN       NaN       NaN        NaN   \n",
       "male S                  NaN       NaN       NaN       NaN        NaN   \n",
       "Q^2                     NaN       NaN       NaN       NaN        NaN   \n",
       "Q S                     NaN       NaN       NaN       NaN        NaN   \n",
       "S^2                     NaN       NaN       NaN       NaN        NaN   \n",
       "\n",
       "                Age Parch  Age Fare  Age youngin  Age male     Age Q  \\\n",
       "Pclass           0.040453  0.563423     0.106688  0.101962  0.187702   \n",
       "Age              0.155352  0.369975     0.388210  0.554774  0.013247   \n",
       "SibSp            0.196140  0.053909     0.306183  0.216614  0.061042   \n",
       "Parch            0.849833  0.137806     0.294849  0.273704  0.074582   \n",
       "Fare             0.218098  0.915077     0.014188  0.100407  0.105209   \n",
       "youngin          0.034359  0.134128     0.813867  0.267628  0.065881   \n",
       "male             0.199376  0.141902     0.080499  0.799071  0.055060   \n",
       "Q                0.056467  0.111645     0.002904  0.088859  0.922553   \n",
       "S                0.039057  0.168878     0.046986  0.093232  0.460594   \n",
       "Pclass^2         0.037702  0.532830     0.101798  0.094240  0.194454   \n",
       "Pclass Age       0.120157  0.190517     0.326432  0.399919  0.187331   \n",
       "Pclass SibSp     0.175627  0.032648     0.324682  0.203037  0.048857   \n",
       "Pclass Parch     0.789112  0.006420     0.314677  0.267669  0.051041   \n",
       "Pclass Fare      0.326124  0.792253     0.096264  0.178302  0.099921   \n",
       "Pclass youngin   0.032028  0.131336     0.820343  0.259669  0.062614   \n",
       "Pclass male      0.204955  0.306674     0.040737  0.563567  0.009666   \n",
       "Pclass Q         0.054432  0.120291     0.000843  0.091573  0.898680   \n",
       "Pclass S         0.023027  0.328368     0.085732  0.031316  0.388099   \n",
       "Age^2            0.155876  0.364175     0.239851  0.550294  0.009765   \n",
       "Age SibSp        0.296359  0.209805     0.012360  0.102452  0.046897   \n",
       "Age Parch             NaN  0.272346     0.002226  0.106678  0.036348   \n",
       "Age Fare              NaN       NaN     0.102809  0.039378  0.090104   \n",
       "Age youngin           NaN       NaN          NaN  0.206298  0.048280   \n",
       "Age male              NaN       NaN          NaN       NaN  0.013687   \n",
       "Age Q                 NaN       NaN          NaN       NaN       NaN   \n",
       "Age S                 NaN       NaN          NaN       NaN       NaN   \n",
       "SibSp^2               NaN       NaN          NaN       NaN       NaN   \n",
       "SibSp Parch           NaN       NaN          NaN       NaN       NaN   \n",
       "SibSp Fare            NaN       NaN          NaN       NaN       NaN   \n",
       "SibSp youngin         NaN       NaN          NaN       NaN       NaN   \n",
       "SibSp male            NaN       NaN          NaN       NaN       NaN   \n",
       "SibSp Q               NaN       NaN          NaN       NaN       NaN   \n",
       "SibSp S               NaN       NaN          NaN       NaN       NaN   \n",
       "Parch^2               NaN       NaN          NaN       NaN       NaN   \n",
       "Parch Fare            NaN       NaN          NaN       NaN       NaN   \n",
       "Parch youngin         NaN       NaN          NaN       NaN       NaN   \n",
       "Parch male            NaN       NaN          NaN       NaN       NaN   \n",
       "Parch Q               NaN       NaN          NaN       NaN       NaN   \n",
       "Parch S               NaN       NaN          NaN       NaN       NaN   \n",
       "Fare^2                NaN       NaN          NaN       NaN       NaN   \n",
       "Fare youngin          NaN       NaN          NaN       NaN       NaN   \n",
       "Fare male             NaN       NaN          NaN       NaN       NaN   \n",
       "Fare Q                NaN       NaN          NaN       NaN       NaN   \n",
       "Fare S                NaN       NaN          NaN       NaN       NaN   \n",
       "youngin^2             NaN       NaN          NaN       NaN       NaN   \n",
       "youngin male          NaN       NaN          NaN       NaN       NaN   \n",
       "youngin Q             NaN       NaN          NaN       NaN       NaN   \n",
       "youngin S             NaN       NaN          NaN       NaN       NaN   \n",
       "male^2                NaN       NaN          NaN       NaN       NaN   \n",
       "male Q                NaN       NaN          NaN       NaN       NaN   \n",
       "male S                NaN       NaN          NaN       NaN       NaN   \n",
       "Q^2                   NaN       NaN          NaN       NaN       NaN   \n",
       "Q S                   NaN       NaN          NaN       NaN       NaN   \n",
       "S^2                   NaN       NaN          NaN       NaN       NaN   \n",
       "\n",
       "                   Age S   SibSp^2  SibSp Parch  SibSp Fare  SibSp youngin  \\\n",
       "Pclass          0.133358  0.122429     0.124839    0.121130       0.130312   \n",
       "Age             0.571350  0.177076     0.223325    0.100850       0.379725   \n",
       "SibSp           0.105437  0.881671     0.880982    0.759063       0.500619   \n",
       "Parch           0.062866  0.320331     0.562534    0.360956       0.275563   \n",
       "Fare            0.096499  0.101183     0.149266    0.412955       0.001683   \n",
       "youngin         0.282117  0.192279     0.298199    0.119316       0.746455   \n",
       "male            0.130360  0.038549     0.087380    0.108696       0.021002   \n",
       "Q               0.377009  0.017411     0.052160    0.049320       0.038161   \n",
       "S               0.755135  0.079273     0.112448    0.029275       0.030600   \n",
       "Pclass^2        0.150149  0.127982     0.129742    0.107790       0.131574   \n",
       "Pclass Age      0.431156  0.100048     0.139269    0.198253       0.322947   \n",
       "Pclass SibSp    0.112776  0.906735     0.892544    0.655490       0.525636   \n",
       "Pclass Parch    0.062751  0.368958     0.591449    0.292451       0.316781   \n",
       "Pclass Fare     0.124716  0.370917     0.423276    0.556697       0.147206   \n",
       "Pclass youngin  0.274409  0.217137     0.322838    0.123895       0.791833   \n",
       "Pclass male     0.041347  0.009109     0.034939    0.116768       0.025152   \n",
       "Pclass Q        0.373769  0.017707     0.050585    0.056603       0.040965   \n",
       "Pclass S        0.508399  0.139326     0.169171    0.012721       0.085753   \n",
       "Age^2           0.537624  0.135159     0.153858    0.068312       0.223275   \n",
       "Age SibSp       0.068827  0.743856     0.674600    0.725147       0.029853   \n",
       "Age Parch       0.117779  0.148198     0.349610    0.227939       0.018185   \n",
       "Age Fare        0.030858  0.017322     0.041464    0.263627       0.097471   \n",
       "Age youngin     0.208648  0.189303     0.288588    0.108611       0.672642   \n",
       "Age male        0.385994  0.120916     0.173940    0.137725       0.192830   \n",
       "Age Q           0.347811  0.043646     0.070282    0.055482       0.038900   \n",
       "Age S                NaN  0.058150     0.065924    0.052354       0.208215   \n",
       "SibSp^2              NaN       NaN     0.909229    0.733831       0.334351   \n",
       "SibSp Parch          NaN       NaN          NaN    0.748915       0.451933   \n",
       "SibSp Fare           NaN       NaN          NaN         NaN       0.208862   \n",
       "SibSp youngin        NaN       NaN          NaN         NaN            NaN   \n",
       "SibSp male           NaN       NaN          NaN         NaN            NaN   \n",
       "SibSp Q              NaN       NaN          NaN         NaN            NaN   \n",
       "SibSp S              NaN       NaN          NaN         NaN            NaN   \n",
       "Parch^2              NaN       NaN          NaN         NaN            NaN   \n",
       "Parch Fare           NaN       NaN          NaN         NaN            NaN   \n",
       "Parch youngin        NaN       NaN          NaN         NaN            NaN   \n",
       "Parch male           NaN       NaN          NaN         NaN            NaN   \n",
       "Parch Q              NaN       NaN          NaN         NaN            NaN   \n",
       "Parch S              NaN       NaN          NaN         NaN            NaN   \n",
       "Fare^2               NaN       NaN          NaN         NaN            NaN   \n",
       "Fare youngin         NaN       NaN          NaN         NaN            NaN   \n",
       "Fare male            NaN       NaN          NaN         NaN            NaN   \n",
       "Fare Q               NaN       NaN          NaN         NaN            NaN   \n",
       "Fare S               NaN       NaN          NaN         NaN            NaN   \n",
       "youngin^2            NaN       NaN          NaN         NaN            NaN   \n",
       "youngin male         NaN       NaN          NaN         NaN            NaN   \n",
       "youngin Q            NaN       NaN          NaN         NaN            NaN   \n",
       "youngin S            NaN       NaN          NaN         NaN            NaN   \n",
       "male^2               NaN       NaN          NaN         NaN            NaN   \n",
       "male Q               NaN       NaN          NaN         NaN            NaN   \n",
       "male S               NaN       NaN          NaN         NaN            NaN   \n",
       "Q^2                  NaN       NaN          NaN         NaN            NaN   \n",
       "Q S                  NaN       NaN          NaN         NaN            NaN   \n",
       "S^2                  NaN       NaN          NaN         NaN            NaN   \n",
       "\n",
       "                SibSp male   SibSp Q   SibSp S   Parch^2  Parch Fare  \\\n",
       "Pclass            0.088556  0.072570  0.100380  0.054779    0.212234   \n",
       "Age               0.189881  0.107698  0.210078  0.031981    0.021493   \n",
       "SibSp             0.726267  0.228826  0.927300  0.230900    0.281970   \n",
       "Parch             0.254191  0.024159  0.411382  0.874698    0.619486   \n",
       "Fare              0.081588  0.004786  0.119534  0.130052    0.584153   \n",
       "youngin           0.259781  0.194758  0.270745  0.144344    0.104191   \n",
       "male              0.233383  0.027175  0.090338  0.181811    0.129879   \n",
       "Q                 0.016014  0.388075  0.119612  0.038392    0.074095   \n",
       "S                 0.052548  0.193750  0.239579  0.059787    0.003909   \n",
       "Pclass^2          0.091305  0.077647  0.101184  0.057062    0.197777   \n",
       "Pclass Age        0.148226  0.070814  0.148459  0.042230    0.173591   \n",
       "Pclass SibSp      0.724823  0.236845  0.917785  0.226689    0.202377   \n",
       "Pclass Parch      0.289279  0.041532  0.447279  0.884309    0.407403   \n",
       "Pclass Fare       0.291048  0.052073  0.383677  0.276330    0.601863   \n",
       "Pclass youngin    0.282429  0.221248  0.289813  0.136333    0.075708   \n",
       "Pclass male       0.239657  0.054546  0.048820  0.159764    0.183466   \n",
       "Pclass Q          0.013198  0.371576  0.118584  0.036480    0.072916   \n",
       "Pclass S          0.089975  0.163255  0.256783  0.081362    0.083967   \n",
       "Age^2             0.128502  0.074148  0.150857  0.000838    0.021652   \n",
       "Age SibSp         0.550890  0.091180  0.776287  0.217430    0.278080   \n",
       "Age Parch         0.097121  0.020295  0.206722  0.880640    0.599484   \n",
       "Age Fare          0.012074  0.026760  0.026212  0.105279    0.496139   \n",
       "Age youngin       0.223110  0.211401  0.249945  0.129299    0.076514   \n",
       "Age male          0.031318  0.057508  0.178005  0.171053    0.106513   \n",
       "Age Q             0.031683  0.228691  0.110349  0.021217    0.068575   \n",
       "Age S             0.082631  0.146308  0.017505  0.027638    0.017675   \n",
       "SibSp^2           0.660997  0.136869  0.872031  0.174297    0.224229   \n",
       "SibSp Parch       0.616444  0.086349  0.881379  0.406667    0.396544   \n",
       "SibSp Fare        0.522061  0.082810  0.709712  0.215262    0.576619   \n",
       "SibSp youngin     0.426476  0.341759  0.409240  0.120176    0.085215   \n",
       "SibSp male             NaN  0.279313  0.659679  0.125778    0.157558   \n",
       "SibSp Q                NaN       NaN  0.046418  0.010937    0.010037   \n",
       "SibSp S                NaN       NaN       NaN  0.244020    0.268553   \n",
       "Parch^2                NaN       NaN       NaN       NaN    0.509057   \n",
       "Parch Fare             NaN       NaN       NaN       NaN         NaN   \n",
       "Parch youngin          NaN       NaN       NaN       NaN         NaN   \n",
       "Parch male             NaN       NaN       NaN       NaN         NaN   \n",
       "Parch Q                NaN       NaN       NaN       NaN         NaN   \n",
       "Parch S                NaN       NaN       NaN       NaN         NaN   \n",
       "Fare^2                 NaN       NaN       NaN       NaN         NaN   \n",
       "Fare youngin           NaN       NaN       NaN       NaN         NaN   \n",
       "Fare male              NaN       NaN       NaN       NaN         NaN   \n",
       "Fare Q                 NaN       NaN       NaN       NaN         NaN   \n",
       "Fare S                 NaN       NaN       NaN       NaN         NaN   \n",
       "youngin^2              NaN       NaN       NaN       NaN         NaN   \n",
       "youngin male           NaN       NaN       NaN       NaN         NaN   \n",
       "youngin Q              NaN       NaN       NaN       NaN         NaN   \n",
       "youngin S              NaN       NaN       NaN       NaN         NaN   \n",
       "male^2                 NaN       NaN       NaN       NaN         NaN   \n",
       "male Q                 NaN       NaN       NaN       NaN         NaN   \n",
       "male S                 NaN       NaN       NaN       NaN         NaN   \n",
       "Q^2                    NaN       NaN       NaN       NaN         NaN   \n",
       "Q S                    NaN       NaN       NaN       NaN         NaN   \n",
       "S^2                    NaN       NaN       NaN       NaN         NaN   \n",
       "\n",
       "                Parch youngin  Parch male   Parch Q   Parch S    Fare^2  \\\n",
       "Pclass               0.087608    0.004332  0.060982  0.039831  0.283651   \n",
       "Age                  0.479864    0.144809  0.017762  0.150332  0.060165   \n",
       "SibSp                0.328443    0.370575  0.057643  0.429773  0.032466   \n",
       "Parch                0.384992    0.540849  0.211702  0.887374  0.098984   \n",
       "Fare                 0.010266    0.172737  0.012433  0.153882  0.866095   \n",
       "youngin              0.932918    0.301518  0.069037  0.309346  0.030607   \n",
       "male                 0.076694    0.222525  0.040944  0.209780  0.077515   \n",
       "Q                    0.036905    0.053632  0.239979  0.123057  0.055465   \n",
       "S                    0.052414    0.037252  0.119812  0.246478  0.138231   \n",
       "Pclass^2             0.080784    0.006891  0.063651  0.036069  0.265324   \n",
       "Pclass Age           0.417410    0.152054  0.035168  0.091407  0.170097   \n",
       "Pclass SibSp         0.341674    0.369161  0.066449  0.419668  0.016223   \n",
       "Pclass Parch         0.385722    0.484476  0.248915  0.855977  0.003790   \n",
       "Pclass Fare          0.125394    0.293392  0.028279  0.335311  0.779464   \n",
       "Pclass youngin       0.898197    0.285387  0.079615  0.291499  0.037830   \n",
       "Pclass male          0.049005    0.177699  0.022324  0.175457  0.153102   \n",
       "Pclass Q             0.035294    0.051946  0.246057  0.121999  0.057365   \n",
       "Pclass S             0.079690    0.048882  0.100954  0.221725  0.188472   \n",
       "Age^2                0.279739    0.058419  0.010685  0.079199  0.050204   \n",
       "Age SibSp            0.026705    0.250546  0.000981  0.342293  0.054920   \n",
       "Age Parch            0.022263    0.415603  0.220841  0.762557  0.112827   \n",
       "Age Fare             0.123248    0.127907  0.016724  0.087192  0.802463   \n",
       "Age youngin          0.786072    0.224068  0.076944  0.282425  0.030324   \n",
       "Age male             0.249989    0.056711  0.060843  0.240830  0.039022   \n",
       "Age Q                0.064653    0.068547  0.224184  0.113526  0.049864   \n",
       "Age S                0.258902    0.074344  0.090474  0.068407  0.093824   \n",
       "SibSp^2              0.201596    0.310317  0.041418  0.344335  0.015913   \n",
       "SibSp Parch          0.337288    0.437771  0.030431  0.588410  0.051949   \n",
       "SibSp Fare           0.131678    0.291162  0.011701  0.356249  0.229251   \n",
       "SibSp youngin        0.731771    0.275649  0.128600  0.260123  0.024977   \n",
       "SibSp male           0.239607    0.549493  0.086491  0.262863  0.000270   \n",
       "SibSp Q              0.120711    0.085615  0.320582  0.047755  0.015138   \n",
       "SibSp S              0.297508    0.358501  0.028704  0.486181  0.016907   \n",
       "Parch^2              0.186006    0.387636  0.266701  0.805467  0.055431   \n",
       "Parch Fare           0.137544    0.434722  0.051056  0.525030  0.441081   \n",
       "Parch youngin             NaN    0.317638  0.040474  0.356711  0.022466   \n",
       "Parch male                NaN         NaN  0.033861  0.497190  0.092528   \n",
       "Parch Q                   NaN         NaN       NaN  0.029531  0.012208   \n",
       "Parch S                   NaN         NaN       NaN       NaN  0.049586   \n",
       "Fare^2                    NaN         NaN       NaN       NaN       NaN   \n",
       "Fare youngin              NaN         NaN       NaN       NaN       NaN   \n",
       "Fare male                 NaN         NaN       NaN       NaN       NaN   \n",
       "Fare Q                    NaN         NaN       NaN       NaN       NaN   \n",
       "Fare S                    NaN         NaN       NaN       NaN       NaN   \n",
       "youngin^2                 NaN         NaN       NaN       NaN       NaN   \n",
       "youngin male              NaN         NaN       NaN       NaN       NaN   \n",
       "youngin Q                 NaN         NaN       NaN       NaN       NaN   \n",
       "youngin S                 NaN         NaN       NaN       NaN       NaN   \n",
       "male^2                    NaN         NaN       NaN       NaN       NaN   \n",
       "male Q                    NaN         NaN       NaN       NaN       NaN   \n",
       "male S                    NaN         NaN       NaN       NaN       NaN   \n",
       "Q^2                       NaN         NaN       NaN       NaN       NaN   \n",
       "Q S                       NaN         NaN       NaN       NaN       NaN   \n",
       "S^2                       NaN         NaN       NaN       NaN       NaN   \n",
       "\n",
       "                Fare youngin  Fare male    Fare Q    Fare S  youngin^2  \\\n",
       "Pclass              0.006150   0.307680  0.074089  0.377868   0.104190   \n",
       "Age                 0.398010   0.106764  0.041303  0.058655   0.517150   \n",
       "SibSp               0.274142   0.094406  0.083622  0.257639   0.330293   \n",
       "Parch               0.306256   0.098136  0.020580  0.295555   0.346635   \n",
       "Fare                0.079512   0.600099  0.015989  0.510889   0.008379   \n",
       "youngin             0.762911   0.003537  0.035769  0.050270   1.000000   \n",
       "male                0.040138   0.331042  0.040576  0.125189   0.076252   \n",
       "Q                   0.018686   0.076967  0.669023  0.183991   0.021512   \n",
       "S                   0.053434   0.074817  0.334017  0.368528   0.040392   \n",
       "Pclass^2            0.002886   0.290548  0.082158  0.364083   0.095793   \n",
       "Pclass Age          0.351442   0.177123  0.010142  0.245582   0.450017   \n",
       "Pclass SibSp        0.267952   0.053188  0.071119  0.163923   0.342410   \n",
       "Pclass Parch        0.257603   0.008844  0.000998  0.154152   0.353128   \n",
       "Pclass Fare         0.154134   0.569566  0.004408  0.515470   0.105895   \n",
       "Pclass youngin      0.654945   0.010824  0.047570  0.019583   0.975276   \n",
       "Pclass male         0.040506   0.065119  0.011624  0.222932   0.044231   \n",
       "Pclass Q            0.017112   0.081519  0.589012  0.182410   0.019381   \n",
       "Pclass S            0.031950   0.161536  0.281444  0.038802   0.072309   \n",
       "Age^2               0.229577   0.120535  0.041785  0.079452   0.300358   \n",
       "Age SibSp           0.026270   0.119885  0.065557  0.299244   0.037465   \n",
       "Age Parch           0.025276   0.119994  0.012875  0.271279   0.034359   \n",
       "Age Fare            0.098446   0.580436  0.015351  0.433579   0.134128   \n",
       "Age youngin         0.585055   0.011231  0.050544  0.033515   0.813867   \n",
       "Age male            0.203961   0.323095  0.056472  0.074934   0.267628   \n",
       "Age Q               0.050693   0.069819  0.638909  0.169742   0.065881   \n",
       "Age S               0.216000   0.021423  0.252228  0.319378   0.282117   \n",
       "SibSp^2             0.163054   0.080430  0.035908  0.197588   0.192279   \n",
       "SibSp Parch         0.262532   0.085060  0.008635  0.272525   0.298199   \n",
       "SibSp Fare          0.152356   0.186843  0.042406  0.481473   0.119316   \n",
       "SibSp youngin       0.608096   0.022365  0.106277  0.045677   0.746455   \n",
       "SibSp male          0.230582   0.244075  0.111371  0.168748   0.259781   \n",
       "SibSp Q             0.140344   0.022065  0.620009  0.071402   0.194758   \n",
       "SibSp S             0.239360   0.088858  0.080023  0.328478   0.270745   \n",
       "Parch^2             0.145545   0.054760  0.006799  0.204360   0.144344   \n",
       "Parch Fare          0.205852   0.384409  0.037754  0.551756   0.104191   \n",
       "Parch youngin       0.799714   0.013690  0.008658  0.076845   0.932918   \n",
       "Parch male          0.288329   0.360873  0.009721  0.211455   0.301518   \n",
       "Parch Q             0.049436   0.012877  0.299101  0.044154   0.069037   \n",
       "Parch S             0.294136   0.056396  0.082328  0.384694   0.309346   \n",
       "Fare^2              0.014580   0.608850  0.021692  0.251364   0.030607   \n",
       "Fare youngin             NaN   0.071868  0.023950  0.171710   0.762911   \n",
       "Fare male                NaN        NaN  0.005299  0.259302   0.003537   \n",
       "Fare Q                   NaN        NaN       NaN  0.123094   0.035769   \n",
       "Fare S                   NaN        NaN       NaN       NaN   0.050270   \n",
       "youngin^2                NaN        NaN       NaN       NaN        NaN   \n",
       "youngin male             NaN        NaN       NaN       NaN        NaN   \n",
       "youngin Q                NaN        NaN       NaN       NaN        NaN   \n",
       "youngin S                NaN        NaN       NaN       NaN        NaN   \n",
       "male^2                   NaN        NaN       NaN       NaN        NaN   \n",
       "male Q                   NaN        NaN       NaN       NaN        NaN   \n",
       "male S                   NaN        NaN       NaN       NaN        NaN   \n",
       "Q^2                      NaN        NaN       NaN       NaN        NaN   \n",
       "Q S                      NaN        NaN       NaN       NaN        NaN   \n",
       "S^2                      NaN        NaN       NaN       NaN        NaN   \n",
       "\n",
       "                youngin male  youngin Q  youngin S    male^2    male Q  \\\n",
       "Pclass              0.065358   0.055478   0.075229  0.127741  0.162164   \n",
       "Age                 0.369544   0.121038   0.453500  0.083730  0.038506   \n",
       "SibSp               0.285900   0.211839   0.291855  0.116348  0.017057   \n",
       "Parch               0.237868   0.051491   0.319470  0.247508  0.071040   \n",
       "Fare                0.003584   0.004022   0.001711  0.179958  0.080826   \n",
       "youngin             0.705735   0.245536   0.882095  0.076252  0.024016   \n",
       "male                0.142093   0.049437   0.059933  1.000000  0.161690   \n",
       "Q                   0.026371   0.218319   0.074375  0.075217  0.714047   \n",
       "S                   0.038097   0.108998   0.148970  0.121405  0.356495   \n",
       "Pclass^2            0.059274   0.057906   0.066065  0.131843  0.169108   \n",
       "Pclass Age          0.321905   0.100463   0.395362  0.173907  0.097958   \n",
       "Pclass SibSp        0.295107   0.225889   0.298273  0.082424  0.030679   \n",
       "Pclass Parch        0.238891   0.066362   0.319323  0.221790  0.054611   \n",
       "Pclass Fare         0.094790   0.046778   0.101995  0.185347  0.062459   \n",
       "Pclass youngin      0.678357   0.275788   0.840024  0.078243  0.035012   \n",
       "Pclass male         0.153170   0.074055   0.037505  0.867233  0.229977   \n",
       "Pclass Q            0.028805   0.223848   0.073736  0.072493  0.712636   \n",
       "Pclass S            0.055718   0.091842   0.168242  0.161356  0.300385   \n",
       "Age^2               0.212379   0.073104   0.264660  0.075746  0.031240   \n",
       "Age SibSp           0.019803   0.025636   0.033193  0.144453  0.026908   \n",
       "Age Parch           0.029186   0.010109   0.025533  0.199376  0.063868   \n",
       "Age Fare            0.094845   0.031651   0.117158  0.141902  0.078409   \n",
       "Age youngin         0.527130   0.261206   0.745539  0.080499  0.039129   \n",
       "Age male            0.169086   0.053247   0.235276  0.799071  0.090640   \n",
       "Age Q               0.038618   0.026208   0.068615  0.055060  0.691357   \n",
       "Age S               0.202154   0.082308   0.236427  0.130360  0.269202   \n",
       "SibSp^2             0.184327   0.152475   0.169446  0.038549  0.013285   \n",
       "SibSp Parch         0.237206   0.116478   0.289015  0.087380  0.017161   \n",
       "SibSp Fare          0.117528   0.076815   0.114263  0.108696  0.018905   \n",
       "SibSp youngin       0.618822   0.411142   0.659323  0.021002  0.090635   \n",
       "SibSp male          0.412710   0.284612   0.220559  0.233383  0.082752   \n",
       "SibSp Q             0.287954   0.857708   0.028863  0.027175  0.405362   \n",
       "SibSp S             0.225254   0.026114   0.327073  0.090338  0.085409   \n",
       "Parch^2             0.093628   0.004992   0.140169  0.181811  0.054084   \n",
       "Parch Fare          0.080545   0.007753   0.107400  0.129879  0.055365   \n",
       "Parch youngin       0.644156   0.158307   0.851766  0.076694  0.000173   \n",
       "Parch male          0.467105   0.112643   0.287670  0.222525  0.013497   \n",
       "Parch Q             0.107786   0.334781   0.017848  0.040944  0.119263   \n",
       "Parch S             0.221178   0.026866   0.370874  0.209780  0.087868   \n",
       "Fare^2              0.019683   0.010273   0.023604  0.077515  0.039420   \n",
       "Fare youngin        0.584623   0.177762   0.717244  0.040138  0.015271   \n",
       "Fare male           0.086392   0.022945   0.011093  0.331042  0.016296   \n",
       "Fare Q              0.086231   0.336962   0.049758  0.040576  0.499889   \n",
       "Fare S              0.049073   0.040169   0.094393  0.125189  0.131378   \n",
       "youngin^2           0.705735   0.245536   0.882095  0.076252  0.024016   \n",
       "youngin male             NaN   0.347916   0.641303  0.142093  0.072672   \n",
       "youngin Q                NaN        NaN   0.016237  0.049437  0.305749   \n",
       "youngin S                NaN        NaN        NaN  0.059933  0.053107   \n",
       "male^2                   NaN        NaN        NaN       NaN  0.161690   \n",
       "male Q                   NaN        NaN        NaN       NaN       NaN   \n",
       "male S                   NaN        NaN        NaN       NaN       NaN   \n",
       "Q^2                      NaN        NaN        NaN       NaN       NaN   \n",
       "Q S                      NaN        NaN        NaN       NaN       NaN   \n",
       "S^2                      NaN        NaN        NaN       NaN       NaN   \n",
       "\n",
       "                  male S       Q^2  Q S       S^2  \n",
       "Pclass          0.131041  0.220558  NaN  0.076466  \n",
       "Age             0.056530  0.080875  NaN  0.013598  \n",
       "SibSp           0.067642  0.026692  NaN  0.069438  \n",
       "Parch           0.174840  0.081585  NaN  0.061512  \n",
       "Fare            0.207436  0.116684  NaN  0.163758  \n",
       "youngin         0.042008  0.021512  NaN  0.040392  \n",
       "male            0.729575  0.075217  NaN  0.121405  \n",
       "Q               0.305526  1.000000  NaN  0.499261  \n",
       "S               0.611956  0.499261  NaN  1.000000  \n",
       "Pclass^2        0.123467  0.229168  NaN  0.051742  \n",
       "Pclass Age      0.166454  0.103448  NaN  0.107301  \n",
       "Pclass SibSp    0.040569  0.007634  NaN  0.079964  \n",
       "Pclass Parch    0.143366  0.056168  NaN  0.071283  \n",
       "Pclass Fare     0.183557  0.100328  NaN  0.099595  \n",
       "Pclass youngin  0.048685  0.012337  NaN  0.029044  \n",
       "Pclass male     0.656714  0.001700  NaN  0.132146  \n",
       "Pclass Q        0.302900  0.991406  NaN  0.494970  \n",
       "Pclass S        0.572014  0.420679  NaN  0.842604  \n",
       "Age^2           0.050705  0.088276  NaN  0.015042  \n",
       "Age SibSp       0.094617  0.054624  NaN  0.054818  \n",
       "Age Parch       0.150965  0.056467  NaN  0.039057  \n",
       "Age Fare        0.181548  0.111645  NaN  0.168878  \n",
       "Age youngin     0.048128  0.002904  NaN  0.046986  \n",
       "Age male        0.579605  0.088859  NaN  0.093232  \n",
       "Age Q           0.281864  0.922553  NaN  0.460594  \n",
       "Age S           0.499036  0.377009  NaN  0.755135  \n",
       "SibSp^2         0.002033  0.017411  NaN  0.079273  \n",
       "SibSp Parch     0.026140  0.052160  NaN  0.112448  \n",
       "SibSp Fare      0.059775  0.049320  NaN  0.029275  \n",
       "SibSp youngin   0.014386  0.038161  NaN  0.030600  \n",
       "SibSp male      0.191910  0.016014  NaN  0.052548  \n",
       "SibSp Q         0.118567  0.388075  NaN  0.193750  \n",
       "SibSp S         0.032614  0.119612  NaN  0.239579  \n",
       "Parch^2         0.117503  0.038392  NaN  0.059787  \n",
       "Parch Fare      0.110548  0.074095  NaN  0.003909  \n",
       "Parch youngin   0.036159  0.036905  NaN  0.052414  \n",
       "Parch male      0.171496  0.053632  NaN  0.037252  \n",
       "Parch Q         0.073320  0.239979  NaN  0.119812  \n",
       "Parch S         0.077980  0.123057  NaN  0.246478  \n",
       "Fare^2          0.126522  0.055465  NaN  0.138231  \n",
       "Fare youngin    0.010107  0.018686  NaN  0.053434  \n",
       "Fare male       0.138743  0.076967  NaN  0.074817  \n",
       "Fare Q          0.204404  0.669023  NaN  0.334017  \n",
       "Fare S          0.063313  0.183991  NaN  0.368528  \n",
       "youngin^2       0.042008  0.021512  NaN  0.040392  \n",
       "youngin male    0.122297  0.026371  NaN  0.038097  \n",
       "youngin Q       0.066702  0.218319  NaN  0.108998  \n",
       "youngin S       0.016689  0.074375  NaN  0.148970  \n",
       "male^2          0.729575  0.075217  NaN  0.121405  \n",
       "male Q          0.218160  0.714047  NaN  0.356495  \n",
       "male S               NaN  0.305526  NaN  0.611956  \n",
       "Q^2                  NaN       NaN  NaN  0.499261  \n",
       "Q S                  NaN       NaN  NaN       NaN  \n",
       "S^2                  NaN       NaN  NaN       NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = X_poly.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find index of feature columns with correlation greater than 0.90\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.97)]\n",
    "X_poly.drop(columns=to_drop, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>youngin</th>\n",
       "      <th>male</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "      <th>Pclass Age</th>\n",
       "      <th>Pclass Parch</th>\n",
       "      <th>Pclass Fare</th>\n",
       "      <th>Pclass male</th>\n",
       "      <th>Pclass S</th>\n",
       "      <th>Age^2</th>\n",
       "      <th>Age SibSp</th>\n",
       "      <th>Age Parch</th>\n",
       "      <th>Age Fare</th>\n",
       "      <th>Age youngin</th>\n",
       "      <th>Age male</th>\n",
       "      <th>Age Q</th>\n",
       "      <th>Age S</th>\n",
       "      <th>SibSp^2</th>\n",
       "      <th>SibSp Parch</th>\n",
       "      <th>SibSp Fare</th>\n",
       "      <th>SibSp youngin</th>\n",
       "      <th>SibSp male</th>\n",
       "      <th>SibSp Q</th>\n",
       "      <th>SibSp S</th>\n",
       "      <th>Parch^2</th>\n",
       "      <th>Parch Fare</th>\n",
       "      <th>Parch youngin</th>\n",
       "      <th>Parch male</th>\n",
       "      <th>Parch Q</th>\n",
       "      <th>Parch S</th>\n",
       "      <th>Fare^2</th>\n",
       "      <th>Fare youngin</th>\n",
       "      <th>Fare male</th>\n",
       "      <th>Fare Q</th>\n",
       "      <th>Fare S</th>\n",
       "      <th>youngin male</th>\n",
       "      <th>youngin Q</th>\n",
       "      <th>youngin S</th>\n",
       "      <th>male Q</th>\n",
       "      <th>male S</th>\n",
       "      <th>Q S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.7500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>484.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.562500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2708.7654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5081.308859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.7750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>206.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.805625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1225.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1858.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2819.610000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1225.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>281.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.802500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age  SibSp  Parch     Fare  youngin  male    Q    S  Pclass Age  \\\n",
       "0     3.0  22.0    1.0    0.0   7.2500      0.0   1.0  0.0  1.0        66.0   \n",
       "1     1.0  38.0    1.0    0.0  71.2833      0.0   0.0  0.0  0.0        38.0   \n",
       "2     3.0  26.0    0.0    0.0   7.9250      0.0   0.0  0.0  1.0        78.0   \n",
       "3     1.0  35.0    1.0    0.0  53.1000      0.0   0.0  0.0  1.0        35.0   \n",
       "4     3.0  35.0    0.0    0.0   8.0500      0.0   1.0  0.0  1.0       105.0   \n",
       "\n",
       "   Pclass Parch  Pclass Fare  Pclass male  Pclass S   Age^2  Age SibSp  \\\n",
       "0           0.0      21.7500          3.0       3.0   484.0       22.0   \n",
       "1           0.0      71.2833          0.0       0.0  1444.0       38.0   \n",
       "2           0.0      23.7750          0.0       3.0   676.0        0.0   \n",
       "3           0.0      53.1000          0.0       1.0  1225.0       35.0   \n",
       "4           0.0      24.1500          3.0       3.0  1225.0        0.0   \n",
       "\n",
       "   Age Parch   Age Fare  Age youngin  Age male  Age Q  Age S  SibSp^2  \\\n",
       "0        0.0   159.5000          0.0      22.0    0.0   22.0      1.0   \n",
       "1        0.0  2708.7654          0.0       0.0    0.0    0.0      1.0   \n",
       "2        0.0   206.0500          0.0       0.0    0.0   26.0      0.0   \n",
       "3        0.0  1858.5000          0.0       0.0    0.0   35.0      1.0   \n",
       "4        0.0   281.7500          0.0      35.0    0.0   35.0      0.0   \n",
       "\n",
       "   SibSp Parch  SibSp Fare  SibSp youngin  SibSp male  SibSp Q  SibSp S  \\\n",
       "0          0.0      7.2500            0.0         1.0      0.0      1.0   \n",
       "1          0.0     71.2833            0.0         0.0      0.0      0.0   \n",
       "2          0.0      0.0000            0.0         0.0      0.0      0.0   \n",
       "3          0.0     53.1000            0.0         0.0      0.0      1.0   \n",
       "4          0.0      0.0000            0.0         0.0      0.0      0.0   \n",
       "\n",
       "   Parch^2  Parch Fare  Parch youngin  Parch male  Parch Q  Parch S  \\\n",
       "0      0.0         0.0            0.0         0.0      0.0      0.0   \n",
       "1      0.0         0.0            0.0         0.0      0.0      0.0   \n",
       "2      0.0         0.0            0.0         0.0      0.0      0.0   \n",
       "3      0.0         0.0            0.0         0.0      0.0      0.0   \n",
       "4      0.0         0.0            0.0         0.0      0.0      0.0   \n",
       "\n",
       "        Fare^2  Fare youngin  Fare male  Fare Q  Fare S  youngin male  \\\n",
       "0    52.562500           0.0       7.25     0.0   7.250           0.0   \n",
       "1  5081.308859           0.0       0.00     0.0   0.000           0.0   \n",
       "2    62.805625           0.0       0.00     0.0   7.925           0.0   \n",
       "3  2819.610000           0.0       0.00     0.0  53.100           0.0   \n",
       "4    64.802500           0.0       8.05     0.0   8.050           0.0   \n",
       "\n",
       "   youngin Q  youngin S  male Q  male S  Q S  \n",
       "0        0.0        0.0     0.0     1.0  0.0  \n",
       "1        0.0        0.0     0.0     0.0  0.0  \n",
       "2        0.0        0.0     0.0     0.0  0.0  \n",
       "3        0.0        0.0     0.0     0.0  0.0  \n",
       "4        0.0        0.0     0.0     1.0  0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_poly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889, 46)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'youngin', 'male', 'Q', 'S',\n",
       "       'Pclass Age', 'Pclass Parch', 'Pclass Fare', 'Pclass male', 'Pclass S',\n",
       "       'Age^2', 'Age SibSp', 'Age Parch', 'Age Fare', 'Age youngin',\n",
       "       'Age male', 'Age Q', 'Age S', 'SibSp^2', 'SibSp Parch', 'SibSp Fare',\n",
       "       'SibSp youngin', 'SibSp male', 'SibSp Q', 'SibSp S', 'Parch^2',\n",
       "       'Parch Fare', 'Parch youngin', 'Parch male', 'Parch Q', 'Parch S',\n",
       "       'Fare^2', 'Fare youngin', 'Fare male', 'Fare Q', 'Fare S',\n",
       "       'youngin male', 'youngin Q', 'youngin S', 'male Q', 'male S', 'Q S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_poly.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use x and y variables to split the training data into train and test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class predictions (not predicted probabilities)\n",
    "y_pred_class = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8116591928251121\n"
     ]
    }
   ],
   "source": [
    "lr_acc = metrics.accuracy_score(y_test, y_pred_class)\n",
    "print('Accuracy Score:', lr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.98660111, -0.2055155 ,  0.00432313,  1.27319967,  0.45745576,\n",
       "         0.44062606, -1.45574933,  0.24338452, -0.56870916, -0.30500757,\n",
       "        -0.5698578 ,  0.27651151,  1.05927237,  0.05046454, -0.23031218,\n",
       "         0.24611161, -0.43998389,  0.33062233, -0.2334754 , -0.24260083,\n",
       "         0.21399748,  0.96922046, -0.68591949,  0.42942134,  0.43903349,\n",
       "        -0.43521412, -0.2085734 ,  0.38018001, -0.58257175, -0.00289117,\n",
       "        -0.41457396,  0.38813948, -0.16329885, -1.07233465, -0.33341551,\n",
       "        -0.75123106, -0.32467556, -0.10876237,  0.06708845, -0.11478495,\n",
       "         0.90497173, -0.33257101, -0.01216712, -0.69018986, -0.4895146 ,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_coef_df = pd.DataFrame(data=logreg.coef_)\n",
    "lr_coef_df.columns = X_poly.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.986601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.205515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>0.004323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>1.273200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.457456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youngin</th>\n",
       "      <td>0.440626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>-1.455749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q</th>\n",
       "      <td>0.243385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>-0.568709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass Age</th>\n",
       "      <td>-0.305008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass Parch</th>\n",
       "      <td>-0.569858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass Fare</th>\n",
       "      <td>0.276512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass male</th>\n",
       "      <td>1.059272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass S</th>\n",
       "      <td>0.050465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age^2</th>\n",
       "      <td>-0.230312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age SibSp</th>\n",
       "      <td>0.246112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age Parch</th>\n",
       "      <td>-0.439984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age Fare</th>\n",
       "      <td>0.330622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age youngin</th>\n",
       "      <td>-0.233475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age male</th>\n",
       "      <td>-0.242601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age Q</th>\n",
       "      <td>0.213997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age S</th>\n",
       "      <td>0.969220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp^2</th>\n",
       "      <td>-0.685919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp Parch</th>\n",
       "      <td>0.429421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp Fare</th>\n",
       "      <td>0.439033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp youngin</th>\n",
       "      <td>-0.435214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp male</th>\n",
       "      <td>-0.208573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp Q</th>\n",
       "      <td>0.380180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp S</th>\n",
       "      <td>-0.582572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch^2</th>\n",
       "      <td>-0.002891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch Fare</th>\n",
       "      <td>-0.414574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch youngin</th>\n",
       "      <td>0.388139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch male</th>\n",
       "      <td>-0.163299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch Q</th>\n",
       "      <td>-1.072335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch S</th>\n",
       "      <td>-0.333416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare^2</th>\n",
       "      <td>-0.751231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare youngin</th>\n",
       "      <td>-0.324676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare male</th>\n",
       "      <td>-0.108762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare Q</th>\n",
       "      <td>0.067088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare S</th>\n",
       "      <td>-0.114785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youngin male</th>\n",
       "      <td>0.904972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youngin Q</th>\n",
       "      <td>-0.332571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youngin S</th>\n",
       "      <td>-0.012167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male Q</th>\n",
       "      <td>-0.690190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male S</th>\n",
       "      <td>-0.489515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q S</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "Pclass        -0.986601\n",
       "Age           -0.205515\n",
       "SibSp          0.004323\n",
       "Parch          1.273200\n",
       "Fare           0.457456\n",
       "youngin        0.440626\n",
       "male          -1.455749\n",
       "Q              0.243385\n",
       "S             -0.568709\n",
       "Pclass Age    -0.305008\n",
       "Pclass Parch  -0.569858\n",
       "Pclass Fare    0.276512\n",
       "Pclass male    1.059272\n",
       "Pclass S       0.050465\n",
       "Age^2         -0.230312\n",
       "Age SibSp      0.246112\n",
       "Age Parch     -0.439984\n",
       "Age Fare       0.330622\n",
       "Age youngin   -0.233475\n",
       "Age male      -0.242601\n",
       "Age Q          0.213997\n",
       "Age S          0.969220\n",
       "SibSp^2       -0.685919\n",
       "SibSp Parch    0.429421\n",
       "SibSp Fare     0.439033\n",
       "SibSp youngin -0.435214\n",
       "SibSp male    -0.208573\n",
       "SibSp Q        0.380180\n",
       "SibSp S       -0.582572\n",
       "Parch^2       -0.002891\n",
       "Parch Fare    -0.414574\n",
       "Parch youngin  0.388139\n",
       "Parch male    -0.163299\n",
       "Parch Q       -1.072335\n",
       "Parch S       -0.333416\n",
       "Fare^2        -0.751231\n",
       "Fare youngin  -0.324676\n",
       "Fare male     -0.108762\n",
       "Fare Q         0.067088\n",
       "Fare S        -0.114785\n",
       "youngin male   0.904972\n",
       "youngin Q     -0.332571\n",
       "youngin S     -0.012167\n",
       "male Q        -0.690190\n",
       "male S        -0.489515\n",
       "Q S            0.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_coef_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_coef_df = lr_coef_df.T.sort_values(by=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = lr_coef_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>-1.455749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>1.273200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch Q</th>\n",
       "      <td>-1.072335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass male</th>\n",
       "      <td>1.059272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.986601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age S</th>\n",
       "      <td>0.969220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youngin male</th>\n",
       "      <td>0.904972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare^2</th>\n",
       "      <td>-0.751231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male Q</th>\n",
       "      <td>-0.690190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp^2</th>\n",
       "      <td>-0.685919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "male         -1.455749\n",
       "Parch         1.273200\n",
       "Parch Q      -1.072335\n",
       "Pclass male   1.059272\n",
       "Pclass       -0.986601\n",
       "Age S         0.969220\n",
       "youngin male  0.904972\n",
       "Fare^2       -0.751231\n",
       "male Q       -0.690190\n",
       "SibSp^2      -0.685919"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df.iloc[sorted_df[0].abs().argsort()][::-1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_coefs = sum(sorted_df[0].abs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1095df6d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_coef_df.plot(kind='bar', title='Model Coefficients', legend=False, figsize=(16,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficiently searching for optimal tuning parameters ([video #8](https://www.youtube.com/watch?v=Gol_qOgRqfA&list=PL5-da3qGB5ICeMbQuqbbCOQWcS6OYBr5A&index=8))\n",
    "\n",
    "Created by [Data School](http://www.dataschool.io/). Watch all 9 videos on [YouTube](https://www.youtube.com/playlist?list=PL5-da3qGB5ICeMbQuqbbCOQWcS6OYBr5A). Download the notebooks from [GitHub](https://github.com/justmarkham/scikit-learn-videos).\n",
    "\n",
    "**Note:** This notebook uses Python 3.6 and scikit-learn 0.19.1. The original notebook (shown in the video) used Python 2.7 and scikit-learn 0.16, and can be downloaded from the [archive branch](https://github.com/justmarkham/scikit-learn-videos/tree/archive).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "- How can K-fold cross-validation be used to search for an **optimal tuning parameter**?\n",
    "- How can this process be made **more efficient**?\n",
    "- How do you search for **multiple tuning parameters** at once?\n",
    "- What do you do with those tuning parameters before making **real predictions**?\n",
    "- How can the **computational expense** of this process be reduced?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gridsearch CV is a flexible algorithm in sklearn that allows you to search over multiple hyperparameters for a model, to find which combination of hyperparameters creates a model that performs best along some evaluation metric.\n",
    "\n",
    "**Read through the documentation for GridsearchCV and determine which parameters are required for the algorithm to run.**\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How do we alter this object in order to use a specific evaluation metric like precision or recall?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## More efficient parameter tuning using `GridSearchCV`\n",
    "\n",
    "Allows you to define a **grid of parameters** that will be **searched** using K-fold cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrl2 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_range = [0.001, 0.01, 0.1, 1, 10, 100, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': c_range }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(LogisticRegression(penalty='l2'), param_grid, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] .......................................... C=0.001, total=   0.0s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] .......................................... C=0.001, total=   0.0s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] .......................................... C=0.001, total=   0.0s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] .......................................... C=0.001, total=   0.0s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] .......................................... C=0.001, total=   0.0s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] ........................................... C=0.01, total=   0.0s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] ........................................... C=0.01, total=   0.0s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] ........................................... C=0.01, total=   0.0s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] ........................................... C=0.01, total=   0.0s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] ........................................... C=0.01, total=   0.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................................ C=0.1, total=   0.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................................ C=0.1, total=   0.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................................ C=0.1, total=   0.0s\n",
      "[CV] C=0.1 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................................ C=0.1, total=   0.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................................ C=0.1, total=   0.0s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................................. C=1, total=   0.0s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................................. C=1, total=   0.0s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................................. C=1, total=   0.0s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................................. C=1, total=   0.0s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................................. C=1, total=   0.0s\n",
      "[CV] C=10 ............................................................\n",
      "[CV] ............................................. C=10, total=   0.1s\n",
      "[CV] C=10 ............................................................\n",
      "[CV] ............................................. C=10, total=   0.1s\n",
      "[CV] C=10 ............................................................\n",
      "[CV] ............................................. C=10, total=   0.1s\n",
      "[CV] C=10 ............................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................................. C=10, total=   0.1s\n",
      "[CV] C=10 ............................................................\n",
      "[CV] ............................................. C=10, total=   0.1s\n",
      "[CV] C=100 ...........................................................\n",
      "[CV] ............................................ C=100, total=   0.1s\n",
      "[CV] C=100 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................................ C=100, total=   0.1s\n",
      "[CV] C=100 ...........................................................\n",
      "[CV] ............................................ C=100, total=   0.1s\n",
      "[CV] C=100 ...........................................................\n",
      "[CV] ............................................ C=100, total=   0.1s\n",
      "[CV] C=100 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................................ C=100, total=   0.1s\n",
      "[CV] C=1000 ..........................................................\n",
      "[CV] ........................................... C=1000, total=   0.1s\n",
      "[CV] C=1000 ..........................................................\n",
      "[CV] ........................................... C=1000, total=   0.1s\n",
      "[CV] C=1000 ..........................................................\n",
      "[CV] ........................................... C=1000, total=   0.1s\n",
      "[CV] C=1000 ..........................................................\n",
      "[CV] ........................................... C=1000, total=   0.1s\n",
      "[CV] C=1000 ..........................................................\n",
      "[CV] ........................................... C=1000, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# fit the grid with data\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00740471, 0.00866437, 0.01109738, 0.02900181, 0.03549042,\n",
       "        0.03654523, 0.03770189]),\n",
       " 'std_fit_time': array([0.00186406, 0.00230151, 0.00113339, 0.00877233, 0.00279796,\n",
       "        0.00566234, 0.00738816]),\n",
       " 'mean_score_time': array([0.00092931, 0.0006362 , 0.00059757, 0.00069618, 0.0008328 ,\n",
       "        0.00127316, 0.001231  ]),\n",
       " 'std_score_time': array([2.92601338e-04, 1.05851792e-04, 1.48512661e-04, 2.01452103e-04,\n",
       "        9.70074777e-05, 4.17837467e-04, 8.93952227e-04]),\n",
       " 'param_C': masked_array(data=[0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "              mask=[False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.001},\n",
       "  {'C': 0.01},\n",
       "  {'C': 0.1},\n",
       "  {'C': 1},\n",
       "  {'C': 10},\n",
       "  {'C': 100},\n",
       "  {'C': 1000}],\n",
       " 'split0_test_score': array([0.75373134, 0.82089552, 0.80597015, 0.81343284, 0.8358209 ,\n",
       "        0.8358209 , 0.82835821]),\n",
       " 'split1_test_score': array([0.72932331, 0.80451128, 0.78947368, 0.77443609, 0.76691729,\n",
       "        0.7518797 , 0.7518797 ]),\n",
       " 'split2_test_score': array([0.69924812, 0.78947368, 0.79699248, 0.80451128, 0.80451128,\n",
       "        0.80451128, 0.80451128]),\n",
       " 'split3_test_score': array([0.69924812, 0.81203008, 0.82706767, 0.81954887, 0.80451128,\n",
       "        0.81203008, 0.81203008]),\n",
       " 'split4_test_score': array([0.72180451, 0.82706767, 0.81954887, 0.79699248, 0.78947368,\n",
       "        0.78947368, 0.78947368]),\n",
       " 'mean_test_score': array([0.72067108, 0.81079565, 0.80781057, 0.80178431, 0.80024689,\n",
       "        0.79874313, 0.79725059]),\n",
       " 'std_test_score': array([0.02043043, 0.01313339, 0.01389448, 0.01568178, 0.02248913,\n",
       "        0.02780892, 0.0259146 ]),\n",
       " 'rank_test_score': array([7, 1, 2, 3, 4, 5, 6], dtype=int32)}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.720671</td>\n",
       "      <td>0.020430</td>\n",
       "      <td>{'C': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.810796</td>\n",
       "      <td>0.013133</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.807811</td>\n",
       "      <td>0.013894</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.801784</td>\n",
       "      <td>0.015682</td>\n",
       "      <td>{'C': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.800247</td>\n",
       "      <td>0.022489</td>\n",
       "      <td>{'C': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.798743</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>{'C': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.797251</td>\n",
       "      <td>0.025915</td>\n",
       "      <td>{'C': 1000}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_score  std_test_score        params\n",
       "0         0.720671        0.020430  {'C': 0.001}\n",
       "1         0.810796        0.013133   {'C': 0.01}\n",
       "2         0.807811        0.013894    {'C': 0.1}\n",
       "3         0.801784        0.015682      {'C': 1}\n",
       "4         0.800247        0.022489     {'C': 10}\n",
       "5         0.798743        0.027809    {'C': 100}\n",
       "6         0.797251        0.025915   {'C': 1000}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the results as a pandas DataFrame\n",
    "pd.DataFrame(grid.cv_results_)[['mean_test_score', 'std_test_score', 'params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.001}\n",
      "0.7206710806867915\n"
     ]
    }
   ],
   "source": [
    "# examine the first result\n",
    "print(grid.cv_results_['params'][0])\n",
    "print(grid.cv_results_['mean_test_score'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8107956458309955\n",
      "{'C': 0.01}\n",
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Searching multiple parameters simultaneously\n",
    "\n",
    "- **Example:** tuning `max_depth` and `min_samples_leaf` for a `DecisionTreeClassifier`\n",
    "- Could tune parameters **independently**: change `max_depth` while leaving `min_samples_leaf` at its default value, and vice versa\n",
    "- But, best performance might be achieved when **neither parameter** is at its default value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the parameter values that should be searched\n",
    "penalty = ['l1', 'l2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'penalty': ['l1', 'l2']}\n"
     ]
    }
   ],
   "source": [
    "# create a parameter grid: map the parameter names to the values that should be searched\n",
    "param_grid2 = dict(C=c_range, penalty=penalty)\n",
    "print(param_grid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid2 = GridSearchCV(LogisticRegression(), param_grid2, verbose=1, cv=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 14 candidates, totalling 98 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/eric/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done  98 out of  98 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=7, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid2.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8108082706766918\n",
      "{'C': 0.1, 'penalty': 'l2'}\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print(grid2.best_score_)\n",
    "print(grid2.best_params_)\n",
    "print(grid2.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn\n",
    "\n",
    "Use Grid search to find the best hyperparameters for a KNN model. You must use at least 2 different hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params to loop over\n",
    "neighbors = list(range(1,15,2))\n",
    "algos = ['kd_tree', 'brute']\n",
    "metrics = ['euclidean', 'manhattan', 'minkowski']\n",
    "weights = ['']\n",
    "\n",
    "knn_param_grid = {'n_neighbors':neighbors, 'algorithm':algos, 'metric':metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 42 candidates, totalling 294 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 294 out of 294 | elapsed:    2.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=7, error_score=nan,\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'algorithm': ['kd_tree', 'brute'],\n",
       "                         'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
       "                         'n_neighbors': [1, 3, 5, 7, 9, 11, 13]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid3 = GridSearchCV(knn, knn_param_grid, verbose=1, cv=7)\n",
    "grid3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing computational expense using `RandomizedSearchCV`\n",
    "\n",
    "- Searching many different parameters at once may be computationally infeasible\n",
    "- `RandomizedSearchCV` searches a subset of the parameters, and you control the computational \"budget\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'k_range' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-415b671415ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# specify \"parameter distributions\" rather than a \"parameter grid\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mparam_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'k_range' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# specify \"parameter distributions\" rather than a \"parameter grid\"\n",
    "param_dist = dict(n_neighbors=k_range, weights=weight_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_iter controls the number of searches\n",
    "rand = RandomizedSearchCV(knn, param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=5, return_train_score=False)\n",
    "rand.fit(X, y)\n",
    "pd.DataFrame(rand.cv_results_)[['mean_test_score', 'std_test_score', 'params']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the best model\n",
    "print(rand.best_score_)\n",
    "print(rand.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run RandomizedSearchCV 20 times (with n_iter=10) and record the best score\n",
    "best_scores = []\n",
    "for _ in range(20):\n",
    "    rand = RandomizedSearchCV(knn, param_dist, cv=10, scoring='accuracy', n_iter=10, return_train_score=False)\n",
    "    rand.fit(X, y)\n",
    "    best_scores.append(round(rand.best_score_, 3))\n",
    "print(best_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the best model overall\n",
    "\n",
    "Now we two different models where we have found the optimal parameters for the model. But which model performs better overall?  \n",
    "\n",
    "How would we solve this question?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # your code here\n",
    "# pred_l1 = grid.best_estimator_.predict(X_test)\n",
    "# pred_l2 = grid2.best_estimator_.predict(X_test)\n",
    "# pred_knn = grid_k.best_estimator_.predict(X_test)\n",
    "# print(metrics.accuracy_score(y_test, pred_l1))\n",
    "# print(metrics.accuracy_score(y_test, pred_l2))\n",
    "# print(metrics.accuracy_score(y_test, pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- scikit-learn documentation: [Grid search](http://scikit-learn.org/stable/modules/grid_search.html), [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "- Timed example: [Comparing randomized search and grid search](http://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html)\n",
    "- scikit-learn workshop by Andreas Mueller: [Video segment on randomized search](https://youtu.be/0wUF_Ov8b0A?t=17m38s) (3 minutes), [related notebook](https://github.com/amueller/pydata-nyc-advanced-sklearn/blob/master/Chapter%203%20-%20Randomized%20Hyper%20Parameter%20Search.ipynb)\n",
    "- Paper by Yoshua Bengio: [Random Search for Hyper-Parameter Optimization](http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_12 = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
